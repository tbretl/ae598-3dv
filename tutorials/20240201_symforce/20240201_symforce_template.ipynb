{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity â€” Optimization with SymForce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This activity has the following goals:\n",
    "* Learn how to set up and solve a least-squares problem with [SymForce](https://github.com/symforce-org/symforce).\n",
    "* Learn how to describe poses and transformations with [SymForce](https://github.com/symforce-org/symforce)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SymForce ([github](https://github.com/symforce-org/symforce), [docs](https://symforce.org/)) is a library for solving nonlinear least-squares problems that look like this:\n",
    "\n",
    "$$\\underset{x \\in \\mathcal{X}}{\\text{minimize}} \\quad \\frac{1}{2}\\sum_{i=1}^{n} \\| r_i(x) \\|^2. $$\n",
    "\n",
    "Each function $r_1, \\dotsc, r_n$ is called a **residual** and produces a vector of errors that we want to make small. Although we write each $r_i$ (generically) as depending on all of $x$, it will often depend (in problems we care about) only on a small subset of $x$, i.e., only on some of the variables over which we are optimizing. The game of all solvers is to take advantage of the resulting \"sparsity\" to find solutions much more quickly than they otherwise could be found.\n",
    "\n",
    "I want to be clear up front that I have no special love for SymForce (or any other solver). I suggest we use it because, unlike other libraries of this sort, it has a Python interface that is reasonably easy to use and is reasonably well documented. It also allows you, if you like, to autogenerate C++ code that is competitive with other state-of-the-art solvers (e.g., [ceres](http://ceres-solver.org), [g2o](https://github.com/RainerKuemmerle/g2o), and [GTSAM](https://gtsam.org)).\n",
    "\n",
    "I will happily abandon SymForce if something better comes along. So, I try to stay disciplined about using it *only* for optimization and not for anything else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numerical methods\n",
    "import numpy as np\n",
    "\n",
    "# For image processing and visualization of results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For optimization with symforce\n",
    "import symforce\n",
    "symforce.set_epsilon_to_symbol()\n",
    "import symforce.symbolic as sf\n",
    "from symforce.values import Values\n",
    "from symforce.opt.factor import Factor\n",
    "from symforce.opt.optimizer import Optimizer\n",
    "import sym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: least-squares linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to find the parameters $x_0$ and $x_1$ for which the linear model\n",
    "\n",
    "$$b = x_0 + x_1 a$$\n",
    "\n",
    "best fits data of the form\n",
    "\n",
    "$$(a_0, b_0), \\dotsc, (a_{n-1}, b_{n-1})$$\n",
    "\n",
    "where $a_i, b_i \\in \\R$ for all $i\\in\\{0, \\dotsc, n-1\\}$. If we define \"fit\" in the least-squares sense, then it is equivalent to find the parameters $x_0$ and $x_1$ that solve the following least-squares problem:\n",
    "\n",
    "$$\\underset{x_0\\in\\R, \\; x_1\\in\\R}{\\text{minimize}} \\quad \\frac{1}{2}\\sum_{i=1}^{n-1} \\| b_i - (x_0 + x_1 a_i) \\|^2.$$\n",
    "\n",
    "If we define\n",
    "\n",
    "$$ r(x_0, x_1, a, b) = b - (x_0 + x_1 a) $$\n",
    "\n",
    "then can write this problem in standard form as\n",
    "\n",
    "$$\\underset{x\\in\\R^2}{\\text{minimize}} \\quad \\frac{1}{2}\\sum_{i=0}^{n-1} \\| r_i(x) \\|^2$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ r_i(x) = r(x_0, x_1, a_i, b_i) \\quad\\text{for all}\\quad i\\in\\{0, \\dotsc, n-1\\}. $$\n",
    "\n",
    "This problem is a useful example because it has an analytical solution. First, you can check that\n",
    "\n",
    "$$\\frac{1}{2}\\sum_{i=0}^{n-1} \\| r_i(x) \\|^2 = \\frac{1}{2} \\left\\| y - A x  \\right\\|^2$$\n",
    "\n",
    "where\n",
    "\n",
    "$$y = \\begin{bmatrix} b_0 \\\\ \\vdots \\\\ b_{n-1} \\end{bmatrix} \\qquad\\qquad A = \\begin{bmatrix} 1 & a_0 \\\\ \\vdots & \\vdots \\\\ 1 & a_{n-1} \\end{bmatrix} \\qquad\\qquad x = \\begin{bmatrix} x_0 \\\\ x_1 \\end{bmatrix}.$$\n",
    "\n",
    "A necessary condition for optimality is\n",
    "\n",
    "$$\\begin{align*} 0 &= \\left( \\dfrac{\\partial \\left( \\frac{1}{2} \\left\\| y - A x \\right\\|^2 \\right) }{\\partial x} \\right)^T \\\\ &= \\left( \\left(y - A x \\right)^T A \\right)^T \\\\ &= A^T \\left(y - A x \\right) \\\\ &= A^Ty - A^TA x \\end{align*}$$\n",
    "\n",
    "and so the solution, should one exist, is given by\n",
    "\n",
    "$$ x = \\left( A^T A \\right)^{-1} A^T y. $$\n",
    "\n",
    "You'll notice the famous pseudo-inverse\n",
    "\n",
    "$$\\left( A^T A \\right)^{-1} A^T$$\n",
    "\n",
    "appearing in this expression. In practice, you would never want to compute this pseudo-inverse explicitly (the usual thing to do instead is use the QR decomposition), but it will be fine for our example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a random number generator with a particular seed so that our results are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = 0.2\n",
    "x_1 = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample $a$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of points\n",
    "n = 10\n",
    "\n",
    "# Sample a_i from a uniform distribution on the unit interval\n",
    "a = rng.uniform(size=n)\n",
    "\n",
    "# Sample b_i from a normal distribution with mean x_0 + x_1 * a_i and standard deviation sigma\n",
    "sigma = 0.02\n",
    "b = x_0 + x_1 * a + sigma * rng.standard_normal(size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the analytical solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find y\n",
    "y = b.copy()\n",
    "\n",
    "# Find A\n",
    "A = np.column_stack([np.ones_like(a), a])\n",
    "\n",
    "# Estimate x\n",
    "x_analytical = np.linalg.inv(A.T @ A) @ A.T @ y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "at = np.linspace(0., 1.)\n",
    "bt = x_analytical[0] + x_analytical[1] * at\n",
    "ax.plot(at, bt, '-')\n",
    "ax.plot(a, b, '.', markersize=9)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(0., 1.)\n",
    "ax.set_ylim(0., 1.)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the numerical solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the residual function $r(x_0, x_1, a, b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(\n",
    "    x_0: sf.Scalar,\n",
    "    x_1: sf.Scalar,\n",
    "    a: sf.Scalar,\n",
    "    b: sf.Scalar,\n",
    "    epsilon: sf.Scalar,\n",
    ") -> sf.V1:\n",
    "    return sf.V1(b - (x_0 + x_1 * a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two important things to note about this residual function.\n",
    "\n",
    "First, it uses [typing](https://docs.python.org/3/library/typing.html). Every input is listed with its type (e.g., `x_1` is an `sf.Scalar`, which is a number). The output is also given a type (`sf.V1`, which is a vector of length one). These types are prefixed by `sf` because they are defined by SymForce.\n",
    "\n",
    "Second, it is symbolic. In particular, we can evaluate this function with symbolic arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find symbolic residual\n",
    "r = residual(\n",
    "    sf.Symbol('x_0'),\n",
    "    sf.Symbol('x_1'),\n",
    "    sf.Symbol('a_i'),\n",
    "    sf.Symbol('b_i'),\n",
    "    sf.epsilon,\n",
    ")\n",
    "\n",
    "# Show symbolic residual\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with [SymPy](https://www.sympy.org/), on which SymForce is based, we can create a numeric version of this symbolic function using `lambdify`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_num = symforce.util.lambdify(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, for example, we wanted to find the error\n",
    "\n",
    "$$r_0(x) = r(x_0, x_1, a_0, b_0)$$\n",
    "\n",
    "that is associated with our analytical estimate of $x_0$ and $x_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find numeric residual\n",
    "r = residual_num(\n",
    "    x_analytical[0],\n",
    "    x_analytical[1],\n",
    "    a[0],\n",
    "    b[0],\n",
    "    sym.epsilon,\n",
    ")\n",
    "\n",
    "# Show numeric residual\n",
    "print(r)\n",
    "\n",
    "# Check that numeric residual is what we expect it to be\n",
    "assert(np.isclose(r.item(), b[0] - (x_analytical[0] + x_analytical[1] * a[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll have noticed that one argument of the residual function is called `epsilon`. This argument says how close a number needs to be to zero in order to be considered simply zero. It's a tolerance, in other words. Including it allows us to handle singularities â€” i.e., situations in which a function needs to be computed in a different way when one or more inputs take on certain values. Even if we don't use `epsilon` (as in this example), we always need to include it as the last argument to any residual function defined in SymForce.\n",
    "\n",
    "The symbolic version of `epsilon` is `sf.epsilon`. The numeric version of `epsilon` is `sym.epsilon`. Yes, this naming convention (prefixing the numeric version with `sym`) is annoying. Let's see what these two things are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'sf.epsilon = {sf.epsilon} (of type {type(sf.epsilon)})')\n",
    "print(f'sym.epsilon = {sym.epsilon} (of type {type(sym.epsilon)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined our residual function, the next step is to define a set of \"initial values\" that holds **all** problem data â€” both the unknowns ($x_0$ and $x_1$) and the knowns ($a_0, \\dotsc, a_{n-1}$ and $b_0, \\dotsc, b_{n-1}$, as well as `epsilon`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial values with a placeholder (an empty list) to hold pairs a_i, b_i\n",
    "initial_values = Values(\n",
    "    data=[],\n",
    "    x_0=1.,                  # <-- initial guess\n",
    "    x_1=1.,                  # <-- initial guess\n",
    "    epsilon=sym.epsilon,\n",
    ")\n",
    "\n",
    "# Add each pair a_i, b_i to the list of data\n",
    "for i in range(n):\n",
    "    initial_values['data'].append(Values(\n",
    "        a=a[i],             # <-- a_i\n",
    "        b=b[i],             # <-- b_i\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access values the same way you would access elements of a [dictionary](https://docs.python.org/3/tutorial/datastructures.html#dictionaries). Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x_0 and x_1\n",
    "print('x_0 and x_1:')\n",
    "print(initial_values['x_0'])\n",
    "print(initial_values['x_1'])\n",
    "print('')\n",
    "\n",
    "# Get a_3 and b_3\n",
    "print('a_3 and b_3:')\n",
    "print(initial_values['data'][3]['a'])\n",
    "print(initial_values['data'][3]['b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also access a nested value \"by name\" with a single string as follows (see the [documentation on Values](https://symforce.org/tutorials/values_tutorial.html) for more information). Here are two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a_3 and b_3:')\n",
    "print(initial_values['data[3].a'])\n",
    "print(initial_values['data[3].b'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define the full cost function that is being minimized. In other words, for each element $i$ of the sum\n",
    "$$\\sum_{i=0}^{n-1} \\left\\| r_i(x) \\right\\|^2$$\n",
    "we need to say (1) what $r_i$ is and (2) what data $r_i$ depends on. These two things together are called a **factor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = []                    # <-- factors are stored in a list\n",
    "for i in range(n):              # <-- there are n of them (i.e., n elements of the sum)\n",
    "    factors.append(Factor(      # <-- each factor is appended to the list as it is created\n",
    "        residual=residual,      # <-- what r_i is (i.e., the name of the residual function to\n",
    "                                #     which it corresponds - always the same in this example)\n",
    "        keys=[                  # <-- what r_i depends on (i.e., a list that has the names of\n",
    "                                #     the variables at which r_i is evaluated - these must be\n",
    "                                #     listed in the order of r_i's arguments, and must be the\n",
    "                                #     names we defined in \"initial_values\")\n",
    "            'x_0',              # <-- the first argument of r_i is x_0\n",
    "            'x_1',              # <-- the second argument of r_i is x_1\n",
    "            f'data[{i}].a',     # <-- the third argument of r_i is a_i, the \"name\" of which is data[i].a\n",
    "            f'data[{i}].b',     # <-- the fourth argument of r_i is b_i, the \"name\" of which is data[i].b\n",
    "            'epsilon',          # <-- the last argument of r_i is always epsilon\n",
    "        ]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create an **optimizer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer(\n",
    "    factors=factors,                    # <-- list of factors\n",
    "    optimized_keys=['x_0', 'x_1'],      # <-- list of decision variables (names from \"initial_values\")\n",
    "    debug_stats=True,                   # <-- whether or not to compute extra information about each iteration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we ask the optimizer to solve the least-squares problem that we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimizer.optimize(initial_values)\n",
    "assert(result.status == Optimizer.Status.SUCCESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what `result` contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that `result` has an attribute called `optimized_values` that has exactly the same structures as `initial_values` but with values *after* optimization. In particular, assuming the optimizer was successful, we can find the estimates of $x_1$ and $x_2$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the (numerical) solution\n",
    "x_numerical = np.array([\n",
    "    result.optimized_values['x_0'],\n",
    "    result.optimized_values['x_1'],\n",
    "])\n",
    "\n",
    "# Check that the numerical solution is the same as the analytical solution\n",
    "assert(np.allclose(x_numerical, x_analytical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "at = np.linspace(0., 1.)\n",
    "bt_a = x_analytical[0] + x_analytical[1] * at\n",
    "bt_n = x_numerical[0] + x_numerical[1] * at\n",
    "ax.plot(at, bt_a, '-', color='C0', label='analytical', linewidth=1)\n",
    "ax.plot(at, bt_n, '--', color='C2', label='numerical', linewidth=3)\n",
    "ax.plot(a, b, '.', markersize=9, color='C1')\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(0., 1.)\n",
    "ax.set_ylim(0., 1.)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, here are all the steps to find a numerical solution to the least-squares linear regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define residual function\n",
    "def residual(\n",
    "    x_0: sf.Scalar,\n",
    "    x_1: sf.Scalar,\n",
    "    a: sf.Scalar,\n",
    "    b: sf.Scalar,\n",
    "    epsilon: sf.Scalar,\n",
    ") -> sf.V1:\n",
    "    return sf.V1(b - (x_0 + x_1 * a))\n",
    "\n",
    "# Define initial values\n",
    "initial_values = Values(\n",
    "    data=[],\n",
    "    x_0=1.,\n",
    "    x_1=1.,\n",
    "    epsilon=sym.epsilon,\n",
    ")\n",
    "for i in range(n):\n",
    "    initial_values['data'].append(Values(\n",
    "        a=a[i],\n",
    "        b=b[i],\n",
    "    ))\n",
    "\n",
    "# Define factors\n",
    "factors = []\n",
    "for i in range(n):\n",
    "    factors.append(Factor(\n",
    "        residual=residual,\n",
    "        keys=[\n",
    "            'x_0',\n",
    "            'x_1',\n",
    "            f'data[{i}].a',\n",
    "            f'data[{i}].b',\n",
    "            'epsilon',\n",
    "        ]\n",
    "    ))\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer(\n",
    "    factors=factors,\n",
    "    optimized_keys=['x_0', 'x_1'],\n",
    "    debug_stats=True,\n",
    ")\n",
    "\n",
    "# Run optimizer\n",
    "result = optimizer.optimize(initial_values)\n",
    "assert(result.status == Optimizer.Status.SUCCESS)\n",
    "\n",
    "# Get solution\n",
    "x_numerical = np.array([\n",
    "    result.optimized_values['x_0'],\n",
    "    result.optimized_values['x_1'],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: second-order polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to find the parameters $x_0, x_1, x_2 \\in \\R$ for which the second-order polynomial\n",
    "\n",
    "$$b = x_0 + x_1 a + x_2 a^2$$\n",
    "\n",
    "best fits (in the least-squares sense) data of the form\n",
    "\n",
    "$$(a_0, b_0), \\dotsc, (a_{n-1}, b_{n-1})$$\n",
    "\n",
    "where $a_i, b_i \\in \\R$ for all $i\\in\\{0, \\dotsc, n-1\\}$. If we define\n",
    "\n",
    "$$ r(x_0, x_1, x_2, a, b) = b - (x_0 + x_1 a + x_2 a^2) $$\n",
    "\n",
    "then it is equivalent to solve the least-squares problem\n",
    "\n",
    "$$\\underset{x\\in\\R^2}{\\text{minimize}} \\quad \\frac{1}{2}\\sum_{i=0}^{n-1} \\| r_i(x) \\|^2$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ r_i(x) = r(x_0, x_1, x_2, a_i, b_i) \\quad\\text{for all}\\quad i\\in\\{0, \\dotsc, n-1\\}. $$\n",
    "\n",
    "The analytical solution to this problem is\n",
    "\n",
    "$$ x = \\left( A^T A \\right)^{-1} A^T y $$\n",
    "\n",
    "where\n",
    "\n",
    "$$y = \\begin{bmatrix} b_0 \\\\ \\vdots \\\\ b_{n-1} \\end{bmatrix} \\qquad\\qquad A = \\begin{bmatrix} 1 & a_0 & a_0^2 \\\\ \\vdots & \\vdots \\\\ 1 & a_{n-1} & a_{n-1}^2 \\end{bmatrix} \\qquad\\qquad x = \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random number generator with a particular seed so that results are reproducible\n",
    "rng = np.random.default_rng(1)\n",
    "\n",
    "# Choose x\n",
    "(x_0, x_1, x_2) = (0.3, -1., 2.0)\n",
    "\n",
    "# Sample a, b\n",
    "n = 10\n",
    "sigma = 0.02\n",
    "a = rng.uniform(size=n)\n",
    "b = x_0 + x_1 * a + x_2 * a**2 + sigma * rng.standard_normal(size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the analytical solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find y\n",
    "y = b.copy()\n",
    "\n",
    "# Find A\n",
    "A = np.column_stack([np.ones_like(a), a, a**2])\n",
    "\n",
    "# Estimate x\n",
    "x_analytical = np.linalg.inv(A.T @ A) @ A.T @ y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the numerical solution.\n",
    "\n",
    "**FIXME - modify the following code (copy-pasted from the linear regression example) so it solves the second-order polynomial regression problem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# FIXME\n",
    "#\n",
    "\n",
    "# Define residual function\n",
    "def residual(\n",
    "    x_0: sf.Scalar,\n",
    "    x_1: sf.Scalar,\n",
    "    a: sf.Scalar,\n",
    "    b: sf.Scalar,\n",
    "    epsilon: sf.Scalar,\n",
    ") -> sf.V1:\n",
    "    return sf.V1(b - (x_0 + x_1 * a))\n",
    "\n",
    "# Define initial values\n",
    "initial_values = Values(\n",
    "    data=[],\n",
    "    x_0=1.,\n",
    "    x_1=1.,\n",
    "    epsilon=sym.epsilon,\n",
    ")\n",
    "for i in range(n):\n",
    "    initial_values['data'].append(Values(\n",
    "        a=a[i],\n",
    "        b=b[i],\n",
    "    ))\n",
    "\n",
    "# Define factors\n",
    "factors = []\n",
    "for i in range(n):\n",
    "    factors.append(Factor(\n",
    "        residual=residual,\n",
    "        keys=[\n",
    "            'x_0',\n",
    "            'x_1',\n",
    "            f'data[{i}].a',\n",
    "            f'data[{i}].b',\n",
    "            'epsilon',\n",
    "        ]\n",
    "    ))\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer(\n",
    "    factors=factors,                    # <-- list of factors\n",
    "    optimized_keys=['x_0', 'x_1'],        # <-- list of decision variables (names from \"initial_values\")\n",
    "    debug_stats=True,                   # <-- whether or not to show information about each iteration\n",
    ")\n",
    "\n",
    "# Run optimizer\n",
    "result = optimizer.optimize(initial_values)\n",
    "assert(result.status == Optimizer.Status.SUCCESS)\n",
    "\n",
    "# Get solution\n",
    "x_numerical = np.array([\n",
    "    result.optimized_values['x_0'],\n",
    "    result.optimized_values['x_1'],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the analytical and numerical solutions are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.allclose(x_analytical, x_numerical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the numerical solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "at = np.linspace(0., 1.)\n",
    "bt = x_numerical[0] + x_numerical[1] * at + x_numerical[2] * at**2\n",
    "ax.plot(at, bt, '-')\n",
    "ax.plot(a, b, '.', markersize=9)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(0., 1.)\n",
    "ax.set_ylim(0., 1.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: point cloud alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we describe the pose $T_B^A$ of frame $B$ in the coordinates of frame $A$ using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orientation of B in A\n",
    "R_inA_ofB = np.array([\n",
    "    [np.cos(np.pi / 6), -np.sin(np.pi / 6), 0.],\n",
    "    [np.sin(np.pi / 6), np.cos(np.pi / 6), 0.],\n",
    "    [0., 0., 1.],\n",
    "])\n",
    "\n",
    "# Position of B in A\n",
    "p_inA_ofB = np.array([0.5, -0.2, 0.1])\n",
    "\n",
    "# Pose of B in A\n",
    "T_inA_ofB = np.row_stack([\n",
    "    np.column_stack([R_inA_ofB, p_inA_ofB]),\n",
    "    np.concatenate([np.zeros(3), np.ones(1)]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we describe the same pose (numerically) using SymForce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_inA_ofB_sym = sym.Pose3(\n",
    "    R=sym.Rot3.from_rotation_matrix(R_inA_ofB),\n",
    "    t=p_inA_ofB,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at these two things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NumPy:')\n",
    "print(T_inA_ofB)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('SymForce:')\n",
    "print(T_inA_ofB_sym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, SymForce does not represent poses with homogeneous transformation matrices. Instead, it represents them with seven numbers â€” the first four are the elements of a quaternion that describes orientation, and the last three are the coordinates of position. You can recover the homogeneous transformation matrix from a `sym.Pose3` object like this (note the misspelling of \"homogeneous\" as \"homogenous\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(T_inA_ofB_sym.to_homogenous_matrix())\n",
    "assert(np.allclose(T_inA_ofB_sym.to_homogenous_matrix(), T_inA_ofB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we would find the inverse transformation matrix in NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The right way, given R and p\n",
    "T_inB_ofA = np.row_stack([\n",
    "    np.column_stack([R_inA_ofB.T, -R_inA_ofB.T @ p_inA_ofB]),\n",
    "    np.concatenate([np.zeros(3), np.ones(1)]),\n",
    "])\n",
    "\n",
    "# The right way, given only T\n",
    "T_inB_ofA_secondmethod = np.row_stack([\n",
    "    np.column_stack([T_inA_ofB[0:3, 0:3].T, -T_inA_ofB[0:3, 0:3].T @ T_inA_ofB[0:3, 3]]),\n",
    "    np.concatenate([np.zeros(3), np.ones(1)]),\n",
    "])\n",
    "\n",
    "# The wrong way (inefficient and less accurate), given only T\n",
    "T_inB_ofA_thirdmethod = np.linalg.inv(T_inA_ofB)\n",
    "\n",
    "assert(np.allclose(T_inB_ofA, T_inB_ofA_secondmethod))\n",
    "assert(np.allclose(T_inB_ofA, T_inB_ofA_thirdmethod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we would find the inverse transformation matrix in SymPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_inB_ofA_sym = T_inA_ofB_sym.inverse()\n",
    "assert(np.allclose(T_inB_ofA_sym.to_homogenous_matrix(), T_inB_ofA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we would do coordinate transformation (of **points**) in NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_inA = R_inA_ofB @ p_inB + p_inA_ofB\n",
    "print(p_inA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also do it in homogeneous coordinates like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a point\n",
    "p_inB = np.array([1., 2., 3.])\n",
    "\n",
    "# Express the point in homogeneous coordinates\n",
    "p_inB_homog = np.concatenate([p_inB, np.ones(1)])\n",
    "\n",
    "# Perform the transformation\n",
    "p_inA_homog = T_inA_ofB @ p_inB_homog\n",
    "\n",
    "# Extract the transformed point from homogeneous coordinates\n",
    "p_inA = p_inA_homog[0:3]\n",
    "\n",
    "# Show the transformed point\n",
    "print(p_inA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we would do coordinate transformation (of **points**) in SymForce â€” note the use of `*` instead of `@`, and note that conversion to and from homogeneous coordinates is done behind the scenes, if at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_inA_sym = T_inA_ofB_sym * p_inB\n",
    "\n",
    "print(p_inA_sym)\n",
    "assert(np.allclose(p_inA_sym, p_inA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these operations can be performed symbolically (with `sf.` instead of `sym.`) as well. Everything is the same, *except* that we need to wrap positions in `sf.V3` instead of in a NumPy array. Here is an example (a silly one, because we are using numbers instead of symbols):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformation matrix\n",
    "T_inA_ofB_sf = sf.Pose3(\n",
    "    R=sf.Rot3.from_rotation_matrix(R_inA_ofB),\n",
    "    t=sf.V3(p_inA_ofB),\n",
    ")\n",
    "\n",
    "# Show transformation matrix\n",
    "print('T_inA_ofB_sf')\n",
    "print(T_inA_ofB_sf)\n",
    "\n",
    "print('')\n",
    "\n",
    "# Perform coordinate transformation\n",
    "p_inB_sf = sf.V3(p_inB)\n",
    "p_inA_sf = T_inA_ofB_sf * p_inB_sf\n",
    "\n",
    "# Show transformed coordinates\n",
    "print('p_inA_sf')\n",
    "print(p_inA_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are given a description of the same $n$ points in two different frames:\n",
    "\n",
    "$$p^{A}_0, \\dotsc, p^{A}_{n-1} \\qquad\\text{and}\\qquad p^{B}_0, \\dotsc, p^{B}_{n-1}.$$\n",
    "\n",
    "As a challenge, see if you can use SymForce to formulate and solve the following nonlinear least-squares problem:\n",
    "\n",
    "$$\\underset{T_B^A\\in SE(3)}{\\text{minimize}} \\quad \\frac{1}{2}\\sum_{i=0}^{n-1} \\| p^A_i - T_B^A p^B_i \\|^2$$\n",
    "\n",
    "In other words, see if you can solve for the (assumed unknown) transformation matrix $T_B^A$ that describes how the two coordinate representations of these $n$ points are related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random number generator with particular seed\n",
    "rng = np.random.default_rng(2)\n",
    "\n",
    "# Number of points\n",
    "n = 10\n",
    "\n",
    "# How much noise\n",
    "sigma = 0.02\n",
    "\n",
    "# Sample points one by one\n",
    "p_inB = []\n",
    "p_inA = []\n",
    "for i in range(10):\n",
    "    p_inB.append(rng.uniform(size=3))\n",
    "    p_inA.append(R_inA_ofB @ p_inB[-1] + p_inA_ofB + sigma * rng.standard_normal(size=3))\n",
    "p_inB = np.array(p_inB)\n",
    "p_inA = np.array(p_inA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIXME - Formulate and solve problem with SymForce.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
