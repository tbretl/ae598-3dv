{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity: Two-View Reconstruction\n",
    "\n",
    "This activity has the following goal:\n",
    "* Implement the *eight-point algorithm* for two-view reconstruction\n",
    "\n",
    "Two-view reconstruction is the standard way to initialize structure-from-motion. Given feature matches from a pair of images, we want to find the relative camera pose and the relative position in 3D of the points to which the feature matches correspond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frames\n",
    "\n",
    "We work with three different reference frames in this notebook:\n",
    "* Frame $W$ is the world frame\n",
    "* Frame $A$ is the camera frame from which a first image $A$ was taken\n",
    "* Frame $B$ is the camera frame from which a second image $B$ was taken\n",
    "\n",
    "We decribe (for example) the orientation of frame $A$ in frame $W$ as\n",
    "\n",
    "$$ R^W_A \\in SO(3) $$\n",
    "\n",
    "and the position of frame $A$ in frame $W$ as\n",
    "\n",
    "$$ p^W_A \\in \\R^3. $$\n",
    "\n",
    "The inverse transformation is:\n",
    "\n",
    "$$ \\begin{align*} R^A_W &= (R^W_A)^\\top \\\\ p^A_W &= -(R^W_A)^\\top p^W_A. \\end{align*} $$\n",
    "\n",
    "The sequential transformation is:\n",
    "\n",
    "$$ \\begin{align*} R^B_A &= (R^W_B)^\\top R^W_A \\\\ p^B_A &= -(R^W_B)^\\top \\left( p^W_A - p^W_B \\right). \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points in the world\n",
    "\n",
    "We assume there are $n$ points\n",
    "\n",
    "$$ \\mathrm{p}_1, \\dotsc, \\mathrm{p}_n $$\n",
    "\n",
    "in the world that are visible in both images (i.e., that there are $n$ matches between these two images). The coordinates of these points in frame $W$ (for example) are\n",
    "\n",
    "$$ p^W_1, \\dotsc, p^W_n \\in \\R^3. $$\n",
    "\n",
    "Given the coordinates $p^W_i$ of $i$'th point $\\mathrm{p}_i$ in frame $W$, the coordinates $p^A_i$ of this same point in frame $A$ (for example) are\n",
    "\n",
    "$$ p^A_i = R^A_W p^W_i + p^A_W. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points in the images\n",
    "\n",
    "### Camera models\n",
    "\n",
    "The projection of the points\n",
    "\n",
    "$$ \\mathrm{p}_1, \\dotsc, \\mathrm{p}_n $$\n",
    "\n",
    "into image $A$ is\n",
    "\n",
    "$$ a_1, \\dotsc, a_n \\in \\mathbb{R}^2. $$\n",
    "\n",
    "Our camera model tells us that\n",
    "\n",
    "$$ \\lambda_{a_i} \\begin{bmatrix} a_i \\\\ 1 \\end{bmatrix} = K p^A_i $$\n",
    "\n",
    "where $\\lambda_{a_i}$ is the $z$ coordinate (i.e., the third element) of $p^A_i$. That is,\n",
    "\n",
    "$$ p^A_i = \\begin{bmatrix} x \\\\ y \\\\ \\lambda_{a_i} \\end{bmatrix} $$\n",
    "\n",
    "for some $x, y \\in \\mathbb{R}$. This coordinate $\\lambda_{a_i}$ is also called \"a scale factor\" or \"the depth of point $i$ in image $A$.\" In any case, we emphasize that the camera model is not \"equivalence\" but is a strict equality if we write it as we have done here. The projection of the same $n$ points into image $B$ is, similarly,\n",
    "\n",
    "$$ b_1, \\dotsc, b_n \\in \\mathbb{R}^2. $$\n",
    "\n",
    "Again, our camera model tells us that\n",
    "\n",
    "$$ \\lambda_{b_i} \\begin{bmatrix} b_i \\\\ 1 \\end{bmatrix} = K p^B_i $$\n",
    "\n",
    "where $\\lambda_{b_i}$ is the $z$ coordinate of $p^B_i$.\n",
    "\n",
    "### Normalized image coordinates\n",
    "\n",
    "Suppose we are working with a calibrated camera and so we know the camera matrix $K$. Since $K$ is invertible, the camera model for image $A$ can be rewritten as\n",
    "\n",
    "$$ \\lambda_{a_i} \\left( K^{-1} \\begin{bmatrix} a_i \\\\ 1 \\end{bmatrix} \\right) = p^A_i. $$\n",
    "\n",
    "We define\n",
    "\n",
    "$$ \\alpha_i = K^{-1} \\begin{bmatrix} a_i \\\\ 1 \\end{bmatrix} $$\n",
    "\n",
    "and call $\\alpha_i \\in \\mathbb{R}^3$ the *normalized image coordinates* of the projection $a_i \\in \\mathbb{R}^2$ of point $\\mathrm{p}_i$ into image $A$. The camera model for image $A$ is then\n",
    "\n",
    "$$ \\lambda_{a_i} \\alpha_i = p^A_i. $$\n",
    "\n",
    "If we do the same thing for image $B$, the camera model in that case is\n",
    "\n",
    "$$ \\lambda_{b_i} \\beta_i = p^B_i $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\beta_i = K^{-1} \\begin{bmatrix} b_i \\\\ 1 \\end{bmatrix}. $$\n",
    "\n",
    "### Constraints\n",
    "\n",
    "We have the following camera models:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\lambda_{a_i} \\alpha_i &= p^A_i \\\\\n",
    "\\lambda_{b_i} \\beta_i &= p^B_i.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "What relates these two models is the fact that $p^A_i$ and $p^B_i$ are descriptions of the same point $\\mathrm{p}_i$ in different frames. We can make this relationship explicit by rewriting the camera model for image $B$ as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\lambda_{b_i} \\beta_i\n",
    "&= p^B_i \\\\\n",
    "&= R^B_A p^A_i + p^B_A && \\text{by coordinate transformation} \\\\\n",
    "&= R^B_A \\lambda_{a_i} \\alpha_i + p^B_A && \\text{by plugging in our camera model for image $A$} \\\\\n",
    "&= \\lambda_{a_i} R^B_A \\alpha_i + p^B_A.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We now have a set of $3n$ equations\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\lambda_{b_1} \\beta_1 &= \\lambda_{a_1} R^B_A \\alpha_1 + p^B_A \\\\\n",
    "& \\vdots \\\\\n",
    "\\lambda_{b_n} \\beta_n &= \\lambda_{a_n} R^B_A \\alpha_n + p^B_A\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "in $2n+6$ unknowns\n",
    "\n",
    "$$ \\lambda_{a_1}, \\dotsc, \\lambda_{a_n} \\qquad\\qquad \\lambda_{b_1}, \\dotsc, \\lambda_{b_n} \\qquad\\qquad \\left(R^B_A, p^B_A\\right) $$\n",
    "\n",
    "and so have hope that, if the number $n$ of projected points is big enough, we can estimate these unknowns by solving the equations.\n",
    "\n",
    "### Scale ambiguity\n",
    "\n",
    "If\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\lambda_{b_1} \\beta_1 &= \\lambda_{a_1} R^B_A \\alpha_1 + p^B_A \\\\\n",
    "& \\vdots \\\\\n",
    "\\lambda_{b_n} \\beta_n &= \\lambda_{a_n} R^B_A \\alpha_n + p^B_A\n",
    "\\end{align*}\n",
    "$$\n",
    "then\n",
    "$$\n",
    "\\begin{align*}\n",
    "s\\left( \\lambda_{b_1} \\right) \\beta_1 &= s\\left( \\lambda_{a_1} R^B_A \\alpha_1 + p^B_A \\right) \\\\\n",
    "& \\vdots \\\\\n",
    "s\\left( \\lambda_{b_n} \\right) \\beta_n &= s\\left( \\lambda_{a_n} R^B_A \\alpha_n + p^B_A \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "and so\n",
    "$$\n",
    "\\begin{align*}\n",
    "(s\\lambda_{b_1}) \\beta_1 &= (s\\lambda_{a_1}) R^B_A \\alpha_1 + (s p^B_A) \\\\\n",
    "& \\vdots \\\\\n",
    "(s \\lambda_{b_n}) \\beta_n &= (s\\lambda_{a_n}) R^B_A \\alpha_n + (s p^B_A)\n",
    "\\end{align*}\n",
    "$$\n",
    "for any $s \\neq 0$. That is to say, if\n",
    "$$ \\lambda_{a_1}, \\dotsc, \\lambda_{a_n} \\qquad\\qquad \\lambda_{b_1}, \\dotsc, \\lambda_{b_n} \\qquad\\qquad \\left(R^B_A, p^B_A\\right) $$\n",
    "satisfy the constraints, then the \"scaled\" quantities\n",
    "$$ s\\lambda_{a_1}, \\dotsc, s\\lambda_{a_n} \\qquad\\qquad s\\lambda_{b_1}, \\dotsc, s\\lambda_{b_n} \\qquad\\qquad \\left(R^B_A, sp^B_A\\right) $$\n",
    "also satisfy the constraints. In other words, the same (normalized) image coordinates $\\alpha_i, \\beta_i$ would result from frames $A$ and $B$ that are $s$ times farther apart and from a point $\\mathrm{p}_i$ whose $z$ coordinate (i.e., depth) with respect to each frame is $s$ times bigger. This is another example of the usual scale ambiguity we have when working with images. On the plus side, we have one fewer unknown to estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The essential matrix\n",
    "\n",
    "### What the essential matrix is\n",
    "\n",
    "To estimate $R^B_A$ and $p^B_A$, we need to eliminate $\\lambda_{a_i}$ and $\\lambda_{b_i}$ from\n",
    "$$ \\lambda_{b_i} \\beta_i = \\lambda_{a_i} R^B_A \\alpha_i + p^B_A. $$\n",
    "We will do this in two steps.\n",
    "\n",
    "First, take the cross product of $p^B_A$ with both sides:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\widehat{p^B_A} \\lambda_{b_i} \\beta_i\n",
    "&= \\widehat{p^B_A} \\left( \\lambda_{a_i} R^B_A \\alpha_i + p^B_A \\right) \\\\\n",
    "&= \\widehat{p^B_A} \\lambda_{a_i} R^B_A \\alpha_i + \\widehat{p^B_A} p^B_A \\\\\n",
    "&= \\widehat{p^B_A} \\lambda_{a_i} R^B_A \\alpha_i + 0 \\\\\n",
    "&= \\lambda_{a_i} \\widehat{p^B_A} R^B_A \\alpha_i.\n",
    "\\end{align*}\n",
    "$$\n",
    "Here, we made use of the fact that the cross product of a vector with itself is zero.\n",
    "\n",
    "Second, take the dot product of $\\beta_i$ with both sides:\n",
    "$$ \\beta_i^\\top \\left(\\widehat{p^B_A} \\lambda_{b_i} \\beta_i \\right) = \\beta_i^\\top \\left( \\lambda_{a_i} \\widehat{p^B_A} R^B_A \\alpha_i \\right). $$\n",
    "On the left, we have\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\beta_i^\\top \\left(\\widehat{p^B_A} \\lambda_{b_i} \\beta_i \\right)\n",
    "&= \\lambda_{b_i} \\left( \\beta_i^\\top \\widehat{p^B_A} \\beta_i \\right) \\\\\n",
    "&= \\lambda_{b_i} ( 0 ) \\\\\n",
    "&= 0\n",
    "\\end{align*}\n",
    "$$\n",
    "since $\\beta_i$ is perpendicular to $\\widehat{p^B_A} \\beta_i$ and since the dot product of a vector with a perpendicular vector is zero. The equation becomes\n",
    "$$ 0 = \\beta_i^\\top \\left( \\lambda_{a_i} \\widehat{p^B_A} R^B_A \\alpha_i \\right) = \\lambda_{a_i} \\left( \\beta_i^\\top \\widehat{p^B_A} R^B_A \\alpha_i \\right). $$\n",
    "We can divide both sides by $\\lambda_{a_i} \\neq 0$ and arrive at\n",
    "$$ 0 = \\beta_i^\\top \\widehat{p^B_A} R^B_A \\alpha_i. $$\n",
    "The quantity\n",
    "$$ E = \\widehat{p^B_A} R^B_A $$\n",
    "in this expression is called the **essential matrix**.\n",
    "\n",
    "\n",
    "### How to estimate the essential matrix\n",
    "\n",
    "#### Getting an estimate\n",
    "\n",
    "We have $n$ constraints, each of which is linear in $E$:\n",
    "$$\\begin{align*} 0 &= \\beta_1^\\top E \\alpha_1 \\\\ &\\vdots \\\\ 0 &= \\beta_n^\\top E \\alpha_n. \\end{align*}$$\n",
    "These constraints can be rewritten in standard form as\n",
    "$$\\begin{bmatrix} 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} (\\alpha_1 \\otimes \\beta_1)^\\top \\\\ \\vdots \\\\ (\\alpha_n \\otimes \\beta_n)^\\top \\end{bmatrix} \\begin{bmatrix} e_1 \\\\ e_2 \\\\ e_3 \\end{bmatrix}$$\n",
    "where $e_1, e_2, e_3$ are the three **columns** of $E$ and where $\\alpha_i \\otimes \\beta_i$ is the **Kronecker product** of $\\alpha_i$ and $\\beta_i$ (see [Appendix A.1.3 of 3DV](https://i-share-uiu.primo.exlibrisgroup.com/permalink/01CARLI_UIU/gpjosq/alma99506128312205899), for example). SVD can be applied, as usual, to find a non-trivial solution. Let's call this solution $E^{\\prime\\prime}$.\n",
    "\n",
    "#### Normalizing the estimate\n",
    "\n",
    "Clearly, if $E$ satisfies\n",
    "$$0 = \\beta_i^\\top E \\alpha_i$$\n",
    "then so will $sE$ for any $s \\neq 0$:\n",
    "$$0 = s(0) = s \\left(\\beta_i^\\top (sE) \\alpha_i\\right) = \\beta_i^\\top (sE) \\alpha_i.$$\n",
    "This scale ambiguity is the same as what we described already. Remember that\n",
    "$$E = \\widehat{p^B_A} R^B_A$$\n",
    "and so\n",
    "$$sE = s\\left( \\widehat{p^B_A} R^B_A \\right) = \\widehat{(s p^B_A)} R^B_A.$$\n",
    "That is to say, scaling $E$ is equivalent to scaling $p^B_A$ — the same ambiguity we discussed before.\n",
    "So, we will have to make a choice. We *could* choose\n",
    "$$\\| E \\| = 1.$$\n",
    "However, notice that\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\| E \\|\n",
    "&= \\| \\widehat{p^B_A} R^B_A \\| && \\text{by definition} \\\\\n",
    "&= \\| \\widehat{p^B_A} \\| && \\text{since $R^B_A$ is orthonormal} \\\\\n",
    "&= \\sqrt{2} \\| p^B_A \\| && \\text{by direct calculation (try it yourself).}\n",
    "\\end{align*}\n",
    "$$\n",
    "So,\n",
    "$$\\| E \\| = 1$$\n",
    "corresponds to\n",
    "$$\\| p^B_A \\| = 1 / \\sqrt{2}.$$\n",
    "Since the matrix norm of $E$ has no clear meaning, while the vector norm of $p^B_A$ is the distance between frames $A$ and $B$, it probably makes more sense to choose\n",
    "$$\\| E \\| = \\sqrt{2}, $$\n",
    "which corresponds to\n",
    "$$\\| p^B_A \\| = 1.$$\n",
    "To summarize, we normalize our estimate as\n",
    "$$ E^\\prime = \\left( \\sqrt{2} / \\| E^{\\prime\\prime} \\| \\right) E^{\\prime\\prime}. $$\n",
    "\n",
    "\n",
    "#### Correcting the estimate\n",
    "\n",
    "It is a fact (see [Result 9.17 in Chapter 9.6.1 of Hartley and Zisserman](https://i-share-uiu.primo.exlibrisgroup.com/permalink/01CARLI_UIU/gpjosq/alma99692409012205899) or [Theorem 5.5 in Chapter 5.1.2 of 3DV](https://i-share-uiu.primo.exlibrisgroup.com/permalink/01CARLI_UIU/gpjosq/alma99506128312205899), for example) that any essential matrix $E$ satisfying $\\| E \\| = \\sqrt{2}$ has a singular value decomposition\n",
    "$$ E = U S V^\\top $$\n",
    "where $U, V \\in SO(3)$ are rotation matrices and\n",
    "$$ S = \\text{diag} \\left(1, 1, 0\\right). $$\n",
    "Since our method of finding $p^B_A$ and $R^B_A$ will rely on this fact, and since any estimate $E^\\prime$ of $E$ will not actually be an essential matrix, it is important to correct $E^\\prime$ before proceeding so that it has a singular value decomposition of the form given above. The essential matrix $E$ that minimizes $\\|E - E^\\prime\\|$ and that has the structure we require can be found (see [Theorem 5.9 in Chapter 5.2.1 of 3DV](https://i-share-uiu.primo.exlibrisgroup.com/permalink/01CARLI_UIU/gpjosq/alma99506128312205899), for example) by taking the singular decomposition\n",
    "$$ U^\\prime S^\\prime (V^\\prime)^\\top = E^\\prime, $$\n",
    "by extracting the columns of $U^\\prime$ and $V^\\prime$ as\n",
    "$$\n",
    "U^\\prime = \\begin{bmatrix} u_1^\\prime & u_2^\\prime & u_3^\\prime \\end{bmatrix}\n",
    "\\qquad\\qquad\n",
    "V^\\prime = \\begin{bmatrix} v_1^\\prime & v_2^\\prime & v_3^\\prime \\end{bmatrix},\n",
    "$$\n",
    "and by choosing\n",
    "$$\n",
    "\\begin{align*}\n",
    "U &= \\begin{bmatrix} u_1^\\prime & u_2^\\prime & \\det(U^\\prime) u_3^\\prime \\end{bmatrix} \\\\\n",
    "S &= \\text{diag} \\left(1, 1, 0\\right) \\\\\n",
    "V &= \\begin{bmatrix} v_1^\\prime & v_2^\\prime & \\det(V^\\prime) v_3^\\prime \\end{bmatrix}.\n",
    "\\end{align*}\n",
    "$$\n",
    "[Theorem 5.9 in Chapter 5.2.1 of 3DV](https://i-share-uiu.primo.exlibrisgroup.com/permalink/01CARLI_UIU/gpjosq/alma99506128312205899), for example, gives a proof of this result.\n",
    "\n",
    "Note that the way I've suggested to make sure $U, V \\in SO(3)$ — by changing, if necessary, the sign of $u_3^\\prime$ and $v_3^\\prime$ — is different than what is suggested by [Remark 5.10 of 3DV](https://i-share-uiu.primo.exlibrisgroup.com/permalink/01CARLI_UIU/gpjosq/alma99506128312205899). My way is a little more direct, I think. It's clear that if $U$ is orthonormal, then flipping the sign of its third column will flip the sign of its determinant but leave it orthonormal — same for $V$. In general, doing so would change the product $USV^\\top$, and so would produce an invalid decomposition. However, since the third singular value of the essential matrix $E$ is zero, **any** change to the third column of $U$ and $V$ leaves $USV^\\top$ invariant:\n",
    "$$\n",
    "\\begin{align*}\n",
    "USV^\\top &= (1) u_1v_1^\\top + (1) u_2v_2^\\top + (0) u_3v_3^\\top \\\\\n",
    "&= u_1v_1^\\top + u_2v_2^\\top.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### How to decompose the essential matrix\n",
    "\n",
    "#### The four possible decompositions\n",
    "\n",
    "We have an estimate $E$ of the essential matrix that satisfies\n",
    "$$ \\| E \\| = \\sqrt{2} $$\n",
    "and that has the singular value decomposition\n",
    "$$ U S V^\\top = E $$\n",
    "where\n",
    "$$ U, V \\in SO(3) $$\n",
    "are rotation matrices and where\n",
    "$$ S = \\text{diag} \\left(1, 1, 0\\right). $$\n",
    "Now, we want to find the position $p^B_A$ and orientation $R^B_A$ for which\n",
    "$$ E = \\widehat{p^B_A} R^B_A. $$\n",
    "Define the matrix\n",
    "$$ W = \\begin{bmatrix} 0 & -1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}. $$\n",
    "There are exactly two possibilities:\n",
    "\n",
    "* $(R^B_A, p^B_A) = (U W^T V^T, u_3)$\n",
    "* $(R^B_A, p^B_A) = (U W V^T, -u_3)$\n",
    "\n",
    "[Theorem 5.7 in Chapter 5.1.2 of 3DV](https://i-share-uiu.primo.exlibrisgroup.com/permalink/01CARLI_UIU/gpjosq/alma99506128312205899), for example, gives a proof of this result. Since $E$ and $-E$ are \"the same\" up to scale, we have exactly two more possibilities:\n",
    "\n",
    "* $(R^B_A, p^B_A) = (U W^T V^T, -u_3)$\n",
    "* $(R^B_A, p^B_A) = (U W V^T, u_3)$\n",
    "\n",
    "We emphasize that these second two possibilities will satisfy\n",
    "$$ -E = \\widehat{p^B_A} R^B_A $$\n",
    "and not\n",
    "$$ E = \\widehat{p^B_A} R^B_A. $$\n",
    "\n",
    "[Result 9.18 and Result 9.19 in Chapter 9.6.2 of Hartley and Zisserman](https://i-share-uiu.primo.exlibrisgroup.com/permalink/01CARLI_UIU/gpjosq/alma99692409012205899) derive these same four possibilities. I find their derivation a little more confusing, because they couple the pairs that correspond to $+u_3$ and $-u_3$ rather than the pairs that correspond to $E$ and $-E$.\n",
    "\n",
    "#### Choosing amongst the four\n",
    "\n",
    "Which of the four possible decompositions of $E$ should we choose? Remember that this whole story began with the assumption that points $\\mathrm{p}_1, \\dotsc, \\mathrm{p}_n$ are visible in both image $A$ and image $B$. \"Visible\" means \"have positive depth\" — in other words, it must be the case that\n",
    "$$\n",
    "\\lambda_{a_i} > 0 \\text{ and } \\lambda_{b_i} > 0 \\text{ for all } i \\in \\{1, \\dotsc, n\\}.\n",
    "$$\n",
    "This will only be true for *one* of the four possible choices of $R^B_A$ and $p^B_A$, as is explained in [Chapter 9.6.3 of Hartley and Zisserman](https://i-share-uiu.primo.exlibrisgroup.com/permalink/01CARLI_UIU/gpjosq/alma99692409012205899) (for example). So, in order to choose, we will need to estimate $\\lambda_{a_i}$ and $\\lambda_{b_i}$ (equivalently, to estimate $p^A_i$ and $p^B_i$) for all $i \\in \\{1, \\dotsc, n\\}$.\n",
    "\n",
    "### Triangulation\n",
    "\n",
    "Let's return to our governing equation:\n",
    "\n",
    "$$ \\lambda_{b_i} \\beta_i = \\lambda_{a_i} R^B_A \\alpha_i + p^B_A. $$\n",
    "\n",
    "Suppose we know $R^B_A$ and $p^B_A$. The process of estimating $\\lambda_{a_i}$ and $\\lambda_{b_i}$ is known as *triangulation* or as *structure computation*.\n",
    "\n",
    "Given $\\lambda_{a_i}$, it is easy to find $\\lambda_{b_i}$. Remember that\n",
    "$$ \\beta_i = K^{-1} \\begin{bmatrix} b_i \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} u \\\\ v \\\\ 1 \\end{bmatrix}$$\n",
    "for some $u, v \\in \\mathbb{R}$. So,\n",
    "$$\n",
    "\\lambda_{b_i}\n",
    "= \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}^\\top \\left( \\lambda_{b_i} \\beta_i \\right)\n",
    "= \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}^\\top \\left( \\lambda_{a_i} R^B_A \\alpha_i + p^B_A \\right).\n",
    "$$\n",
    "\n",
    "Our strategy, therefore, will be to eliminate $\\lambda_{b_i}$ from the governing equation and solve first for $\\lambda_{a_i}$. We can do this by taking the cross product of $\\beta_i$ with both sides:\n",
    "$$\n",
    "\\begin{align*}\n",
    "0\n",
    "&= \\widehat{\\beta_i} \\lambda_{b_i} \\beta_i && \\text{since the cross product a vector with itself is zero} \\\\\n",
    "&= \\widehat{\\beta_i} \\left( \\lambda_{a_i} R^B_A \\alpha_i + p^B_A \\right) \\\\\n",
    "&= \\left( \\widehat{\\beta_i} R^B_A \\alpha_i \\right) \\lambda_{a_i} + \\widehat{\\beta_i} p^B_A.\n",
    "\\end{align*}\n",
    "$$\n",
    "The least-squares solution is\n",
    "$$ \\lambda_{a_i} = -\\left( \\widehat{\\beta_i} R^B_A \\alpha_i \\right)^\\dagger \\widehat{\\beta_i} p^B_A $$\n",
    "where \"$\\dagger$\" denotes the matrix pseudo-inverse (a.k.a. the \"generalized\" or \"Moore Penrose\" inverse). Since $\\lambda_{a_i} \\in \\mathbb{R}$, we can write this solution more simply as\n",
    "$$ \\lambda_{a_i} = \\frac{u^\\top v}{u^\\top u} $$\n",
    "where\n",
    "$$ u = \\widehat{\\beta_i} R^B_A \\alpha_i $$\n",
    "and\n",
    "$$ v = - \\widehat{\\beta_i} p^B_A.$$\n",
    "\n",
    "Given $\\lambda_{a_i}$ and $\\lambda_{b_i}$, we compute\n",
    "$$\n",
    "p^A_i = \\lambda_{a_i} \\alpha_i\n",
    "\\qquad\\text{and}\\qquad\n",
    "p^B_i = \\lambda_{b_i} \\beta_i.\n",
    "$$\n",
    "\n",
    "\n",
    "### Checking that results are correct\n",
    "\n",
    "We use a synthetic dataset in this notebook, and so have true values to which estimates can be compared.\n",
    "\n",
    "The estimate of $R^B_A$ was exact (i.e., unscaled) and can be compared directly to its true value.\n",
    "\n",
    "The estimates of $p^B_A$, $p^A_1, \\dotsc, p^A_n$, and $p^B_1, \\dotsc, p^B_n$ were all scaled to be consistent with\n",
    "$$ \\| p^B_A \\| = 1. $$\n",
    "\n",
    "If the true distance between frames $A$ and $B$ is $s$ instead of $1$, then we should compare the scaled estimates\n",
    "$sp^B_A$, $sp^A_1, \\dotsc, sp^A_n$, and $sp^B_1, \\dotsc, sp^B_n$\n",
    "to the true values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.linalg import block_diag\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create random number generator with a particular seed so we can reproduce results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that constructs the skew-symmetric matrix\n",
    "\n",
    "$$ \\widehat{v} = \\begin{bmatrix} 0 & -v_3 & v_2 \\\\ v_3 & 0 & -v_1 \\\\ -v_2 & v_1 & 0 \\end{bmatrix} \\in \\mathbb{R}^{3 \\times 3} $$\n",
    "\n",
    "that is associated with a vector\n",
    "\n",
    "$$ v = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix} \\in \\mathbb{R}^3. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew(v):\n",
    "    assert(type(v) == np.ndarray)\n",
    "    assert(v.shape == (3,))\n",
    "    return np.array([[0., -v[2], v[1]],\n",
    "                     [v[2], 0., -v[0]],\n",
    "                     [-v[1], v[0], 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to perform coordinate transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transform(R_inB_ofA, p_inB_ofA, p_inA):\n",
    "    p_inB = np.row_stack([\n",
    "        (R_inB_ofA @ p_inA_i + p_inB_ofA) for p_inA_i in p_inA\n",
    "    ])\n",
    "    return p_inB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to print things nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myprint(M):\n",
    "    if M.shape:\n",
    "        with np.printoptions(linewidth=150, formatter={'float': lambda x: f'{x:10.4f}'}):\n",
    "            print(M)\n",
    "    else:\n",
    "        print(f'{M:10.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose intrinsic parameters, i.e., the camera matrix\n",
    "\n",
    "$$K = \\begin{bmatrix} f_x & 0 & c_x \\\\ 0 & f_y & c_y \\\\ 0 & 0 & 1 \\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([\n",
    "    [1500., 0., 1000.],\n",
    "    [0., 1500., 500.],\n",
    "    [0., 0., 1.],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose extrinsic parameters, i.e., the poses **of frame A in frame W** and **of frame B in frame W**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame A\n",
    "R_inW_ofA = Rotation.from_rotvec((0.05 * np.pi) * np.array([1., 0., 0.])).as_matrix()\n",
    "p_inW_ofA = np.array([0.0, 0.0, -1.0])\n",
    "\n",
    "# Frame B\n",
    "R_inW_ofB = Rotation.from_rotvec((0.05 * np.pi) * np.array([0., 1., 0.])).as_matrix()\n",
    "p_inW_ofB = np.array([0.5, 0.0, -1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find pose **of frame $A$ in frame $B$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_inB_ofA_true = R_inW_ofB.T @ R_inW_ofA\n",
    "p_inB_ofA_true = R_inW_ofB.T @ (p_inW_ofA - p_inW_ofB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample points $p^W_1, \\dotsc, p^W_n$ **in frame W**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "p_inW = rng.uniform(low=[-1., -1., -0.5], high=[1., 1., 2.5], size=(n, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find coordinates $p^A_1, \\dotsc, p^A_n$ and $p^B_1, \\dotsc, p^B_n$ of these same points **in frame $A$** and **in frame $B$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_inA_true = apply_transform(R_inW_ofA.T, -R_inW_ofA.T @ p_inW_ofA, p_inW)\n",
    "p_inB_true = apply_transform(R_inW_ofB.T, -R_inW_ofB.T @ p_inW_ofB, p_inW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project points into the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(K, R_inW_ofC, p_inW_ofC, p_inW):\n",
    "    p_inC = apply_transform(R_inW_ofC.T, -R_inW_ofC.T @ p_inW_ofC, p_inW)\n",
    "    assert(np.all(p_inC[:, 2] > 0))\n",
    "    q = np.row_stack([K @ p_inC_i / p_inC_i[2] for p_inC_i in p_inC])\n",
    "    return q[:, 0:2]\n",
    "\n",
    "a = project(K, R_inW_ofA, p_inW_ofA, p_inW)\n",
    "b = project(K, R_inW_ofB, p_inW_ofB, p_inW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowns:\n",
    "\n",
    "* `a` and `b` are the image coordinates $a_1, \\dotsc, a_n$ and $b_1, \\dotsc, b_n$ of projected points\n",
    "\n",
    "Unknowns:\n",
    "\n",
    "* `p_inA_true` is the true value of $p^A_1, \\dotsc, p^A_n$\n",
    "* `p_inB_true` is the true value of $p^B_1, \\dotsc, p^B_n$\n",
    "* `R_inB_ofA_true` is the true value of $R^B_A$\n",
    "* `p_inB_ofA_true` is the true value of $p^B_A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get reference solution with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate $R^B_A$ and $p^B_A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get solution\n",
    "num_inliers_cv, E_cv, R_inB_ofA_cv, p_inB_ofA_cv, mask_cv = cv2.recoverPose(\n",
    "    a.copy(),\n",
    "    b.copy(),\n",
    "    K, np.zeros(4),\n",
    "    K, np.zeros(4),\n",
    ")\n",
    "\n",
    "# Flatten the position (returned as a 2d array by default)\n",
    "p_inB_ofA_cv = p_inB_ofA_cv.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate $p^A_1, \\dotsc, p^A_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = cv2.triangulatePoints(\n",
    "    K @ np.column_stack([np.eye(3), np.zeros(3)]),\n",
    "    K @ np.column_stack([R_inB_ofA_cv, p_inB_ofA_cv]),\n",
    "    a.copy().T,\n",
    "    b.copy().T,\n",
    ")\n",
    "\n",
    "# Normalize points\n",
    "points /= points[-1, :]\n",
    "\n",
    "# Extract non-homogeneous coordinates\n",
    "p_inA_cv = points[0:3, :].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that results are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative orientation is correct\n",
    "assert(np.allclose(R_inB_ofA_cv, R_inB_ofA_true))\n",
    "\n",
    "# Make sure estimated distance between frame A and frame B is 1\n",
    "assert(np.isclose(np.linalg.norm(p_inB_ofA_cv), 1.))\n",
    "\n",
    "# Find scale\n",
    "s = np.linalg.norm(p_inB_ofA_true)\n",
    "\n",
    "# Apply scale to estimates\n",
    "p_inB_ofA_cv_scaled = s * p_inB_ofA_cv\n",
    "p_inA_cv_scaled = s * p_inA_cv\n",
    "\n",
    "# Scaled estimate of relative position is correct\n",
    "assert(np.allclose(p_inB_ofA_cv_scaled, p_inB_ofA_true))\n",
    "\n",
    "# Scaled estimate of points in frame A is correct\n",
    "assert(np.allclose(p_inA_cv_scaled, p_inA_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get solution with your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to do triangulation (i.e., estimate $p^A_1, \\dotsc, p^A_n$ and $p^B_1, \\dotsc, p^B_n$ given $R^B_A$, $p^B_A$, $\\alpha_1, \\dotsc, \\alpha_n$, and $\\beta_1, \\dotsc, \\beta_n$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulate(alpha, beta, R_inB_ofA, p_inB_ofA):\n",
    "    # Get scales\n",
    "    # ... FIXME ...\n",
    "\n",
    "    # Get points\n",
    "    # ... FIXME ...\n",
    "    p_inA = None\n",
    "    p_inB = None\n",
    "\n",
    "    return p_inA, p_inB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to do two-view reconstruction (i.e., estimate $E$, $R^B_A$, $p^B_A$, $p^A_1, \\dotsc, p^A_n$ and $p^B_1, \\dotsc, p^B_n$ given $a_1, \\dotsc, a_n$, and $b_1, \\dotsc, b_n$). The results should be scaled so that $\\| p^B_A \\| = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoview(a, b, K):\n",
    "    # Normalize image coordinates\n",
    "    # ... FIXME ...\n",
    "\n",
    "    # Estimate essential matrix\n",
    "    # ... FIXME ...\n",
    "\n",
    "    # Normalize essential matrix\n",
    "    # ... FIXME ...\n",
    "\n",
    "    # Correct essential matrix\n",
    "    # ... FIXME ...\n",
    "\n",
    "    # Decompose essential matrix and do triangulation\n",
    "    # - Check first solution (if consistent: return E, R_inB_ofA, p_inB_ofA, p_inA, p_inB)\n",
    "    # ... FIXME ...\n",
    "    # - Check second solution (if consistent: return E, R_inB_ofA, p_inB_ofA, p_inA, p_inB)\n",
    "    # ... FIXME ...\n",
    "    # - Etc.\n",
    "\n",
    "    # Raise exception if no solution was found\n",
    "    raise Exception('Failed to find a solution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function to do two-view reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E, R_inB_ofA, p_inB_ofA, p_inA, p_inB = twoview(a, b, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that results are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative orientation is correct\n",
    "assert(np.allclose(R_inB_ofA, R_inB_ofA_true))\n",
    "\n",
    "# Make sure estimated distance between frame A and frame B is 1\n",
    "assert(np.isclose(np.linalg.norm(p_inB_ofA), 1.))\n",
    "\n",
    "# Find scale\n",
    "s = np.linalg.norm(p_inB_ofA_true)\n",
    "\n",
    "# Apply scale to estimates\n",
    "p_inB_ofA_scaled = s * p_inB_ofA\n",
    "p_inA_scaled = s * p_inA\n",
    "p_inB_scaled = s * p_inB\n",
    "\n",
    "# Scaled estimate of relative position is correct\n",
    "assert(np.allclose(p_inB_ofA_scaled, p_inB_ofA_true))\n",
    "\n",
    "# Scaled estimate of points in frame A is correct\n",
    "assert(np.allclose(p_inA_scaled, p_inA_true))\n",
    "\n",
    "# Scaled estimate of points in frame B is correct\n",
    "assert(np.allclose(p_inB_scaled, p_inB_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "* How many points are required (in general) by your method? In other words, what is the minimum value of $n$ for which your method would still produce a solution? Form and test a hypothesis.\n",
    "* What happens if the origin of frame $A$ and the origin of frame $B$ are at the same point? Would your method still work? Form and test a hypothesis.\n",
    "* Are there arrangements of points (still visible in image $A$ and image $B$) for which your method would fail, even if the number $n$ of points is (in general) big enough? Form and test a hypothesis.\n",
    "* How robust is your method to noisy data? Read [Chapter 11.2 of Hartley and Zisserman](https://i-share-uiu.primo.exlibrisgroup.com/permalink/01CARLI_UIU/gpjosq/alma99692409012205899). Form and test a hypothesis. Consider changing your method, as suggested by the reference text, to make it more robust to noisy data.\n",
    "\n",
    "When you are ready, try applying your method to real data (e.g., to feature matches from a pair of real images) rather than synthetic data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
