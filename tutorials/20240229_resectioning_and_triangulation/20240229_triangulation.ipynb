{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity: Triangulation\n",
    "\n",
    "\"Triangulation\" is the standard way to add new points to an existing reconstruction in structure-from-motion. Given feature matches from a pair of images captured at poses that have already been estimated, we want to find the 3D position of the points to which the feature matches correspond (which we assume are *not* already part of the reconstruction). This is a slight generalization of the method you implemented in the \"two-view reconstruction\" activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem\n",
    "\n",
    "Suppose you know $(R^B_A, p^B_A)$ and $(R^C_A, p^C_A)$. Suppose $n$ points\n",
    "$$ \\mathrm{p}_1, \\dotsc, \\mathrm{p}_n $$\n",
    "are visible in image $B$ with coordinates\n",
    "$$ b_1, \\dotsc, b_n \\in \\mathbb{R}^2 $$\n",
    "and in image $C$ with coordinates\n",
    "$$ c_1, \\dotsc, c_n \\in \\mathbb{R}^2. $$\n",
    "The problem of **triangulation** is to find the coordinates\n",
    "$$ p^A_1, \\dotsc, p^A_n \\in \\mathbb{R}^3 $$\n",
    "of the $n$ points in frame $A$.\n",
    "\n",
    "\n",
    "### The solution\n",
    "\n",
    "You already know how to solve this problem from the activity on two-view reconstruction. Begin by applying sequential transformation to compute the relative pose\n",
    "$$ R^B_C = R^B_A (R^C_A)^\\top \\qquad\\qquad p^B_C = p^B_A - R^B_A (R^C_A)^\\top p^C_A. $$\n",
    "Then, do the following five things for each $i\\in\\{1, \\dotsc, n\\}$.\n",
    "\n",
    "First, compute normalized image coordinates:\n",
    "$$ \\beta_i = K^{-1} \\begin{bmatrix} b_i \\\\ 1 \\end{bmatrix} \\qquad\\qquad \\gamma_i = K^{-1} \\begin{bmatrix} c_i \\\\ 1 \\end{bmatrix}. $$\n",
    "\n",
    "Second, compute the depth\n",
    "$$ \\lambda_{c_i} = \\frac{u^\\top v}{u^\\top u} $$\n",
    "of point $i$ in image $C$, where\n",
    "$$ u = \\widehat{\\beta_i} R^B_C \\gamma_i $$\n",
    "and\n",
    "$$ v = - \\widehat{\\beta_i} p^B_C.$$\n",
    "Check that $\\lambda_{c_i} > 0$ (i.e., that point $i$ is in front of the camera at frame $C$) and either throw an error or discard the point if this condition is violated.\n",
    "\n",
    "Third, compute the depth\n",
    "$$ \\lambda_{b_i} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}^\\top\\left( R^B_C \\gamma_i + p^B_C \\right) $$\n",
    "of point $i$ in image $B$. Check that $\\lambda_{b_i} > 0$ (i.e., that point $i$ is in front of the camera at frame $B$) and either throw an error or discard the point if this condition is violated.\n",
    "\n",
    "Fourth, compute the coordinates\n",
    "$$ p^C_i = \\lambda_{c_i} \\gamma_i $$\n",
    "of point $i$ in frame $C$.\n",
    "\n",
    "Fifth, apply coordinate transformation to compute the coordinates\n",
    "$$ p^A_i = (R^C_A)^\\top \\left( p^C_i - p^C_A \\right) $$\n",
    "of point $i$ in frame $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.linalg import block_diag\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create random number generator with a particular seed so we can reproduce results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that constructs the skew-symmetric matrix\n",
    "\n",
    "$$ \\widehat{v} = \\begin{bmatrix} 0 & -v_3 & v_2 \\\\ v_3 & 0 & -v_1 \\\\ -v_2 & v_1 & 0 \\end{bmatrix} \\in \\mathbb{R}^{3 \\times 3} $$\n",
    "\n",
    "that is associated with a vector\n",
    "\n",
    "$$ v = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix} \\in \\mathbb{R}^3. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew(v):\n",
    "    assert(type(v) == np.ndarray)\n",
    "    assert(v.shape == (3,))\n",
    "    return np.array([[0., -v[2], v[1]],\n",
    "                     [v[2], 0., -v[0]],\n",
    "                     [-v[1], v[0], 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to perform coordinate transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transform(R_inB_ofA, p_inB_ofA, p_inA):\n",
    "    p_inB = np.row_stack([\n",
    "        (R_inB_ofA @ p_inA_i + p_inB_ofA) for p_inA_i in p_inA\n",
    "    ])\n",
    "    return p_inB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to print things nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myprint(M):\n",
    "    if M.shape:\n",
    "        with np.printoptions(linewidth=150, formatter={'float': lambda x: f'{x:10.4f}'}):\n",
    "            print(M)\n",
    "    else:\n",
    "        print(f'{M:10.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose intrinsic parameters, i.e., the camera matrix\n",
    "\n",
    "$$K = \\begin{bmatrix} f_x & 0 & c_x \\\\ 0 & f_y & c_y \\\\ 0 & 0 & 1 \\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([\n",
    "    [1500., 0., 1000.],\n",
    "    [0., 1500., 500.],\n",
    "    [0., 0., 1.],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose extrinsic parameters, i.e., the poses **of frame $A$ in frame $B$** and **of frame $A$ in frame $C$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A in W\n",
    "R_inW_ofA = Rotation.from_rotvec((0.05 * np.pi) * np.array([1., 0., 0.])).as_matrix()\n",
    "p_inW_ofA = np.array([0.0, 0.0, -1.0])\n",
    "\n",
    "# B in W\n",
    "R_inW_ofB = Rotation.from_rotvec((0.05 * np.pi) * np.array([0., 1., 0.])).as_matrix()\n",
    "p_inW_ofB = np.array([0.5, 0.0, -1.1])\n",
    "\n",
    "# C in W\n",
    "R_inW_ofC = Rotation.from_rotvec((0.05 * np.pi) * np.array([0., 0., 1.])).as_matrix()\n",
    "p_inW_ofC = np.array([0.2, -0.1, -0.8])\n",
    "\n",
    "# A in B\n",
    "R_inB_ofA = R_inW_ofB.T @ R_inW_ofA\n",
    "p_inB_ofA = R_inW_ofB.T @ (p_inW_ofA - p_inW_ofB)\n",
    "\n",
    "# A in C\n",
    "R_inC_ofA = R_inW_ofC.T @ R_inW_ofA\n",
    "p_inC_ofA = R_inW_ofC.T @ (p_inW_ofA - p_inW_ofC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample points $p^A_1, \\dotsc, p^A_{n}$. We assume (1) that these points are *not* already part of the reconstruction and (2) that these points are visible in images $B$ and $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "p_inW = rng.uniform(low=[-1., -1., -0.5], high=[1., 1., 2.5], size=(n, 3))\n",
    "p_inA_true = apply_transform(R_inW_ofA.T, -R_inW_ofA.T @ p_inW_ofA, p_inW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project points into images $B$ and $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(K, R_inC_ofA, p_inC_ofA, p_inA):\n",
    "    p_inC = apply_transform(R_inC_ofA, p_inC_ofA, p_inA)\n",
    "    assert(np.all(p_inC[:, 2] > 0))\n",
    "    q = np.row_stack([K @ p_inC_i / p_inC_i[2] for p_inC_i in p_inC])\n",
    "    return q[:, 0:2]\n",
    "\n",
    "b = project(K, R_inB_ofA, p_inB_ofA, p_inA_true)\n",
    "c = project(K, R_inC_ofA, p_inC_ofA, p_inA_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowns:\n",
    "\n",
    "* `b` and `c` are the image coordinates $b_1, \\dotsc, b_n$ and $c_1, \\dotsc, c_n$ of projected points\n",
    "* `R_inB_ofA` and `p_inB_ofA` is the pose of frame $B$ in frame $A$\n",
    "* `R_inC_ofA` and `p_inC_ofA` is the pose of frame $C$ in frame $A$\n",
    "\n",
    "Unknowns:\n",
    "\n",
    "* `p_inA_true` is the true value of $p^A_1, \\dotsc, p^A_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get reference solution with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate $p^A_1, \\dotsc, p^A_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = cv2.triangulatePoints(\n",
    "    K @ np.column_stack([R_inB_ofA, p_inB_ofA]),\n",
    "    K @ np.column_stack([R_inC_ofA, p_inC_ofA]),\n",
    "    b.copy().T,\n",
    "    c.copy().T,\n",
    ")\n",
    "\n",
    "# Normalize points\n",
    "points /= points[-1, :]\n",
    "\n",
    "# Extract non-homogeneous coordinates\n",
    "p_inA_cv = points[0:3, :].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that results are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.allclose(p_inA_cv, p_inA_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get solution with your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to do triangulation (i.e., estimate $p^A_1, \\dotsc, p^A_n$ given $b_1, \\dotsc, b_n$, $c_1, \\dotsc, c_n$, $R^B_A$, $p^B_A$, $R^C_A$, $p^C_A$, and $K$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulate(b, c, R_inB_ofA, p_inB_ofA, R_inC_ofA, p_inC_ofA, K):\n",
    "    # Compute relative pose\n",
    "    # ... FIXME ...\n",
    "\n",
    "    # Compute normalized image coordinates\n",
    "    # ... FIXME ...\n",
    "\n",
    "    # Compute depths in both images and verify (e.g., assert) all are positive\n",
    "    # ... FIXME ...\n",
    "\n",
    "    # Compute points in frame C\n",
    "    # ... FIXME ...\n",
    "\n",
    "    # Compute points in frame A\n",
    "    # ... FIXME ...\n",
    "\n",
    "    p_inA = None\n",
    "\n",
    "    return p_inA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function to do triangulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_inA = triangulate(b, c, R_inB_ofA, p_inB_ofA, R_inC_ofA, p_inC_ofA, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that results are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.allclose(p_inA, p_inA_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "* What happens if the origin of frame $B$ and the origin of frame $C$ are at the same point? Would your method still work? Form and test a hypothesis.\n",
    "* What would cause your method to estimate a negative depth? Would it be better to raise an exception or to discard the point (i.e., not add the point to your reconstruction) in this case?\n",
    "\n",
    "You could also try applying your method to real data (e.g., to feature matches from a third image, given an existing two-view reconstruction from two images) rather than synthetic data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
