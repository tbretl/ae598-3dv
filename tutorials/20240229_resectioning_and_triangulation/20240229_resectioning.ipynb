{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity: Resectioning\n",
    "\n",
    "\"Resectioning\" is the standard way to add a new image to an existing reconstruction in structure-from-motion. Given feature matches from a new image to points whose position has already been estimated, we want to find the camera pose from which the new image was taken. This is also called the \"persepective-$n$-point\" problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem\n",
    "\n",
    "Suppose you know the position\n",
    "$$p^A_1, \\dotsc, p^A_n \\in \\mathbb{R}^3$$\n",
    "of $n$ points in frame $A$. Suppose these same points are visible in image $C$ and that their projection is\n",
    "$$c_1, \\dotsc, c_n \\in \\mathbb{R}^2.$$\n",
    "The problem of **resectioning** is to find the pose $(R^C_A, p^C_A)$ of frame $A$ in frame $C$.\n",
    "\n",
    "### The solution\n",
    "\n",
    "Our camera model is\n",
    "$$ \\lambda_{c_i} \\begin{bmatrix} c_i \\\\ 1 \\end{bmatrix} = K p^C_i = K \\left( R^C_A p^A_i + p^C_A \\right) $$\n",
    "where $\\lambda_{c_i}$ is the $z$ coordinate of $p^C_i$ (i.e., the depth of point $i$ in image $C$). Equivalently, in terms of normalized image coordinates\n",
    "$$ \\gamma_i = K^{-1} \\begin{bmatrix} c_i \\\\ 1 \\end{bmatrix}, $$\n",
    "our camera model is\n",
    "$$ \\lambda_{c_i} \\gamma_i = R^C_A p^A_i + p^C_A. $$\n",
    "To estimate $R^C_A$ and $p^C_A$, we need to eliminate $\\lambda_{c_i}$ from this equation. We can do this by taking the cross product of $\\gamma_i$ with both sides (yet again, we make use of the fact that the cross product of a vector with itself is zero):\n",
    "$$\n",
    "\\begin{align*}\n",
    "0\n",
    "&= \\widehat{\\gamma_i} \\lambda_{c_i} \\gamma_i \\\\\n",
    "&= \\widehat{\\gamma_i} \\left( R^C_A p^A_i + p^C_A \\right) \\\\\n",
    "&= \\widehat{\\gamma_i} R^C_A p^A_i + \\widehat{\\gamma_i} p^C_A.\n",
    "\\end{align*}\n",
    "$$\n",
    "The term\n",
    "$$ \\widehat{\\gamma_i} R^C_A p^A_i $$\n",
    "is linear in\n",
    "$$ R^C_A = \\begin{bmatrix} x^C_A & y^C_A & z^C_A \\end{bmatrix} $$\n",
    "and can be rewritten in terms of the Kronecker product as\n",
    "$$ \\left( p^A_i \\otimes \\widehat{\\gamma_i} \\right) \\begin{bmatrix} x^C_A \\\\ y^C_A \\\\ z^C_A \\end{bmatrix}. $$\n",
    "So, our constraint can be rewritten as\n",
    "$$ 0 = \\begin{bmatrix} p^A_i \\otimes \\widehat{\\gamma_i}  & \\widehat{\\gamma_i} \\end{bmatrix} \\begin{bmatrix} x^C_A \\\\ y^C_A \\\\ z^C_A \\\\ p^C_A \\end{bmatrix}. $$\n",
    "We have one such constraint for each $i \\in \\{1, \\dotsc, n\\}.$ This can all be written in standard form as\n",
    "$$\n",
    "\\begin{bmatrix} 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "p^A_1 \\otimes \\widehat{\\gamma_1}  & \\widehat{\\gamma_1} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "p^A_n \\otimes \\widehat{\\gamma_n}  & \\widehat{\\gamma_n}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} x^C_A \\\\ y^C_A \\\\ z^C_A \\\\ p^C_A \\end{bmatrix}\n",
    "$$\n",
    "and SVD can be used to find a non-trivial solution. This solution will need to be corrected in three ways:\n",
    "\n",
    "* First, divide it (the whole solution, including $p^C_A$) by $\\| x^C_A \\| = 1$ to correct the scale.\n",
    "* Second, multiply it (the whole solution, including $p^C_A$) by $\\det\\left( \\begin{bmatrix} x^C_A & y^C_A & z^C_A \\end{bmatrix} \\right)$ to get a right-handed frame.\n",
    "* Third, define $R^C_A = \\det(UV^\\top) UV^\\top$ where $USV^\\top = \\begin{bmatrix} x^C_A & y^C_A & z^C_A \\end{bmatrix}$ is a singular value decomposition to make sure $R^C_A \\in SO(3)$.\n",
    "\n",
    "There is no scale ambiguity after these three corrections have been made â€” the scale of $p^C_A$ will be consistent with the scale of $p^A_1, \\dotsc, p^A_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "from scipy.linalg import block_diag\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create random number generator with a particular seed so we can reproduce results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that constructs the skew-symmetric matrix\n",
    "\n",
    "$$ \\widehat{v} = \\begin{bmatrix} 0 & -v_3 & v_2 \\\\ v_3 & 0 & -v_1 \\\\ -v_2 & v_1 & 0 \\end{bmatrix} \\in \\mathbb{R}^{3 \\times 3} $$\n",
    "\n",
    "that is associated with a vector\n",
    "\n",
    "$$ v = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix} \\in \\mathbb{R}^3. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew(v):\n",
    "    assert(type(v) == np.ndarray)\n",
    "    assert(v.shape == (3,))\n",
    "    return np.array([[0., -v[2], v[1]],\n",
    "                     [v[2], 0., -v[0]],\n",
    "                     [-v[1], v[0], 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to perform coordinate transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transform(R_inB_ofA, p_inB_ofA, p_inA):\n",
    "    p_inB = np.row_stack([\n",
    "        (R_inB_ofA @ p_inA_i + p_inB_ofA) for p_inA_i in p_inA\n",
    "    ])\n",
    "    return p_inB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to print things nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myprint(M):\n",
    "    if M.shape:\n",
    "        with np.printoptions(linewidth=150, formatter={'float': lambda x: f'{x:10.4f}'}):\n",
    "            print(M)\n",
    "    else:\n",
    "        print(f'{M:10.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose intrinsic parameters, i.e., the camera matrix\n",
    "\n",
    "$$K = \\begin{bmatrix} f_x & 0 & c_x \\\\ 0 & f_y & c_y \\\\ 0 & 0 & 1 \\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([\n",
    "    [1500., 0., 1000.],\n",
    "    [0., 1500., 500.],\n",
    "    [0., 0., 1.],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose extrinsic parameters, i.e., the pose **of frame $A$ in frame $C$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A in W\n",
    "R_inW_ofA = Rotation.from_rotvec((0.05 * np.pi) * np.array([1., 0., 0.])).as_matrix()\n",
    "p_inW_ofA = np.array([0.0, 0.0, -1.0])\n",
    "\n",
    "# C in W\n",
    "R_inW_ofC = Rotation.from_rotvec((0.05 * np.pi) * np.array([0., 0., 1.])).as_matrix()\n",
    "p_inW_ofC = np.array([0.2, -0.1, -0.8])\n",
    "\n",
    "# A in C\n",
    "R_inC_ofA_true = R_inW_ofC.T @ R_inW_ofA\n",
    "p_inC_ofA_true = R_inW_ofC.T @ (p_inW_ofA - p_inW_ofC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample points $p^A_1, \\dotsc, p^A_n$. We assume (1) that these points are already part of a reconstruction, i.e., that their positions have already been estimated and so are \"known,\" and (2) that these points are visible in image $C$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "p_inW = rng.uniform(low=[-1., -1., -0.5], high=[1., 1., 2.5], size=(n, 3))\n",
    "p_inA = apply_transform(R_inW_ofA.T, -R_inW_ofA.T @ p_inW_ofA, p_inW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project points into image $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(K, R_inC_ofA, p_inC_ofA, p_inA):\n",
    "    p_inC = apply_transform(R_inC_ofA, p_inC_ofA, p_inA)\n",
    "    assert(np.all(p_inC[:, 2] > 0))\n",
    "    q = np.row_stack([K @ p_inC_i / p_inC_i[2] for p_inC_i in p_inC])\n",
    "    return q[:, 0:2]\n",
    "\n",
    "c = project(K, R_inC_ofA_true, p_inC_ofA_true, p_inA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowns:\n",
    "\n",
    "* `p_inA` is coordinates $p^A_1, \\dotsc, p^A_n$ of projected points in frame $A$\n",
    "* `c` is coordinates $c_1, \\dotsc, c_n$ of projected points in image $C$\n",
    "\n",
    "Unknowns:\n",
    "\n",
    "* `R_inC_ofA_true` is the true value of $R^C_A$\n",
    "* `p_inC_ofA_true` is the true value of $p^C_A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get reference solution with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate $R^C_A$ and $p^C_A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retval, rvec, tvec = cv2.solvePnP(\n",
    "    p_inA,          # 3D points (in A)\n",
    "    c.copy(),       # 2D points (in image C)\n",
    "    K,              # camera matrix\n",
    "    np.zeros(4),    # distortion coefficients\n",
    ")\n",
    "assert(retval)      # should be True\n",
    "\n",
    "# Convert from rotation vector to rotation matrix\n",
    "R_inC_ofA_cv = Rotation.from_rotvec(rvec.flatten()).as_matrix()\n",
    "\n",
    "# Flatten the position (returned as 2D array by default)\n",
    "p_inC_ofA_cv = tvec.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that results are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orientation is correct\n",
    "assert(np.allclose(R_inC_ofA_cv, R_inC_ofA_true))\n",
    "\n",
    "# Position is correct\n",
    "assert(np.allclose(p_inC_ofA_cv, p_inC_ofA_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get solution with your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to do resectioning (i.e., estimate $R^C_A$ and $p^C_A$ given $p^A_1, \\dotsc, p^A_n$ and $c_1, \\dotsc, c_n$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resection(p_inA, c, K):\n",
    "    # Normalize image coordinates\n",
    "    # ... FIXME ...\n",
    "\n",
    "    # Find solution\n",
    "    # ... FIXME ...\n",
    "\n",
    "    # Correct solution\n",
    "    # - Should have the right scale\n",
    "    # ... FIXME ...\n",
    "    # - Should be right-handed\n",
    "    # ... FIXME ...\n",
    "    # - Should be a rotation matrix\n",
    "    # ... FIXME ...\n",
    "    \n",
    "    R_inC_ofA = np.eye(3)\n",
    "    p_inC_ofA = np.zeros(3)\n",
    "\n",
    "    return R_inC_ofA, p_inC_ofA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function to resection image $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_inC_ofA, p_inC_ofA = resection(p_inA, c, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that results are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orientation is correct\n",
    "assert(np.allclose(R_inC_ofA, R_inC_ofA_true))\n",
    "\n",
    "# Position is correct\n",
    "assert(np.allclose(p_inC_ofA, p_inC_ofA_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "* How many points are required (in general) by your method? In other words, what is the minimum value of $n$ for which your method would still produce a solution? Form and test a hypothesis.\n",
    "* What happens if the origin of frame $A$ and the origin of frame $C$ are at the same point? Would your method still work? Form and test a hypothesis.\n",
    "* Are there arrangements of points (still visible in image $A$ and image $B$) for which your method would fail, even if the number $n$ of points is (in general) big enough? Read [Chapter 12 of Hartley and Zisserman](https://i-share-uiu.primo.exlibrisgroup.com/permalink/01CARLI_UIU/gpjosq/alma99692409012205899). Form and test a hypothesis.\n",
    "* How robust is your method to noisy data? Read [Chapter 7.1 of Hartley and Zisserman](https://i-share-uiu.primo.exlibrisgroup.com/permalink/01CARLI_UIU/gpjosq/alma99692409012205899). Form and test a hypothesis. Consider changing your method, as suggested by the reference text, to make it more robust to noisy data.\n",
    "\n",
    "You could also try applying your method to real data (e.g., to feature matches from a third image, given an existing two-view reconstruction from two images) rather than synthetic data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
