{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-view sparse reconstruction and dense reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import everything *except* our sfm library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import symforce for the sole purpose of setting the value\n",
    "# of epsilon, which must be done first and exactly once.\n",
    "import symforce\n",
    "symforce.set_epsilon_to_symbol()\n",
    "\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import secrets\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import sym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import our sfm library. (Re-evaluate this cell if you make changes to the library.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sfm\n",
    "importlib.reload(sfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When reading video frames\n",
    "frames_to_skip = 30\n",
    "\n",
    "# When matching (max threshold for ratio test)\n",
    "matching_threshold = 0.5\n",
    "\n",
    "# When deciding if triangulated points are invalid\n",
    "max_reprojection_err = 0.75\n",
    "\n",
    "# Camera matrix\n",
    "K = np.array([\n",
    "    [1565.7702703272157, 0.0, 964.2389356041999],\n",
    "    [0.0, 1562.3561924508267, 537.4247202074102],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = secrets.randbits(32)\n",
    "print(f'seeding RNG with {seed}')\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load images from video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify filename\n",
    "video_filename = Path('../../tutorials/20240305_realdata_whatbreaks/video.MOV')\n",
    "\n",
    "# Create a video reader\n",
    "video_src = cv2.VideoCapture(str(video_filename))\n",
    "\n",
    "# Get frame count and frames per second\n",
    "frame_count = int(video_src.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frames_per_second = video_src.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Read frames\n",
    "views = []\n",
    "for i_frame in range(0, frame_count, frames_to_skip):\n",
    "    video_src.set(cv2.CAP_PROP_POS_FRAMES, i_frame)\n",
    "    success, frame = video_src.read()\n",
    "    assert(success)\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    views.append({\n",
    "        'frame_id': i_frame,\n",
    "        'img': img,\n",
    "        'R_inB_ofA': None,\n",
    "        'p_inB_ofA': None,\n",
    "    })\n",
    "print(f'read {len(views)} images from video')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SIFT feature detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Apply detector to find keypoints (pts) and descriptors (desc) in each image\n",
    "for view in views:\n",
    "    pts, desc = sift.detectAndCompute(image=view['img'], mask=None)\n",
    "    view['pts'] = [\n",
    "        {\n",
    "            'pt2d': np.array(pt.pt),\n",
    "            'track': None,\n",
    "        }\n",
    "        for pt in pts\n",
    "    ]\n",
    "    view['desc'] = desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do sparse reconstruction (a.k.a. two-view reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get initial guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = sfm.get_good_matches(views[0]['desc'], views[1]['desc'], threshold=matching_threshold)\n",
    "print(f'found {len(matches)} good matches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = []\n",
    "for match in matches:\n",
    "    track = {\n",
    "        'p_inA': None,\n",
    "        'valid': True,\n",
    "        'matches': [\n",
    "            {'view_id': 0, 'feature_id': match.queryIdx},\n",
    "            {'view_id': 1, 'feature_id': match.trainIdx},\n",
    "        ]\n",
    "    }\n",
    "    tracks.append(track)\n",
    "    views[0]['pts'][match.queryIdx]['track'] = track\n",
    "    views[1]['pts'][match.trainIdx]['track'] = track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get image coordinates of matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a, b\n",
    "a = []\n",
    "b = []\n",
    "for m in matches:\n",
    "    a.append(views[0]['pts'][m.queryIdx]['pt2d'])\n",
    "    b.append(views[1]['pts'][m.trainIdx]['pt2d'])\n",
    "a = np.array(a)\n",
    "b = np.array(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize all good matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "\n",
    "# Show images\n",
    "ax1.imshow(views[0]['img'], cmap='gray')\n",
    "ax2.imshow(views[1]['img'], cmap='gray')\n",
    "\n",
    "# Show matches\n",
    "for a_i, b_i in zip(a, b):\n",
    "    fig.add_artist(\n",
    "        ConnectionPatch(\n",
    "            a_i, b_i, \n",
    "            'data', 'data',\n",
    "            axesA=ax1, axesB=ax2,\\\n",
    "            color='red',\n",
    "            connectionstyle='arc3, rad=0.',\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "    )\n",
    "    # - Draw red dot at each keypoint\n",
    "    ax1.plot(a_i[0], a_i[1], 'r.', markersize=2)\n",
    "    ax2.plot(b_i[0], b_i[1], 'r.', markersize=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate essential matrix\n",
    "E, num_inliers, mask = sfm.getE(a, b, K, rng, threshold=2e-3, num_iters=1000)\n",
    "print(f'found {num_inliers} inliers')\n",
    "\n",
    "# Decompose essential matrix to estimate pose and to triangulate points\n",
    "R_inB_ofA, p_inB_ofA, p_inA = sfm.decomposeE(a, b, K, E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store pose estimates\n",
    "views[0]['R_inB_ofA'] = np.eye(3)\n",
    "views[0]['p_inB_ofA'] = np.zeros(3)\n",
    "views[1]['R_inB_ofA'] = R_inB_ofA\n",
    "views[1]['p_inB_ofA'] = p_inB_ofA\n",
    "\n",
    "# Always make sure zipped lists are the same length\n",
    "assert(len(tracks) == len(p_inA))\n",
    "\n",
    "# Store the position of the point corresponding to each track\n",
    "for track, p_inA_i in zip(tracks, p_inA):\n",
    "    track['p_inA'] = p_inA_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm.show_results(views, tracks, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy results. If you want to start again from here, do the following:\n",
    "\n",
    "```python\n",
    "views, tracks = sfm.copy_results(views_1_ini, tracks_1_ini)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_1_ini, tracks_1_ini = sfm.copy_results(views, tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize (C++)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function that writes data to text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(a):\n",
    "    return ' '.join(str(i) for i in a)\n",
    "\n",
    "def optimizer_cpp_to(views, tracks, K, filename='optimizer_to.txt'):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(f'{K[0, 0]} {K[1, 1]} {K[0, 2]} {K[1, 2]}\\n')\n",
    "        \n",
    "        # For each view that has a pose estimate, add this pose estimate as an initial\n",
    "        # value and (if not the first view) as an optimized key.\n",
    "        s = ''\n",
    "        num_views = 0\n",
    "        for i_view, view in enumerate(views):\n",
    "            if (view['R_inB_ofA'] is None) or (view['p_inB_ofA'] is None):\n",
    "                continue\n",
    "\n",
    "            num_views += 1\n",
    "            T = sym.Pose3(\n",
    "                R=sym.Rot3.from_rotation_matrix(view['R_inB_ofA']),\n",
    "                t=view['p_inB_ofA'],\n",
    "            )\n",
    "            s += f' {i_view} {to_str(T.to_storage())}\\n' # i_view qx qy qz qw x y z\n",
    "        f.write(f'{num_views}\\n')\n",
    "        f.write(s)\n",
    "        \n",
    "        # For each valid track, add its 3d point as an initial value and an optimized\n",
    "        # key, and then, for each match in this track, add its 2d point as an initial\n",
    "        # value and add a factor to penalize reprojection error.\n",
    "        num_tracks = 0\n",
    "        s = ''\n",
    "        for i_track, track in enumerate(tracks):\n",
    "            if not track['valid']:\n",
    "                continue\n",
    "            \n",
    "            num_tracks += 1\n",
    "            p_inA = track['p_inA']\n",
    "            s += f' {i_track} {len(track[\"matches\"])} {to_str(p_inA)}\\n'\n",
    "            for match in track['matches']:\n",
    "                view_id = match['view_id']\n",
    "                feature_id = match['feature_id']\n",
    "                b = views[view_id]['pts'][feature_id]['pt2d']\n",
    "                s += f'  {view_id} {to_str(b)}\\n'\n",
    "        f.write(f'{num_tracks}\\n')\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function that reads data from text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_cpp_from(views, tracks, K, filename='optimizer_from.txt', max_reprojection_err=1.):\n",
    "    with open(filename, 'r') as f:\n",
    "        line = f.readline().split()\n",
    "        num_views = int(line[0])\n",
    "        for i in range(num_views):\n",
    "            line = f.readline().split()\n",
    "            i_view = int(line[0])\n",
    "            tmp = [float(n) for n in line[1:]]\n",
    "            T_inB_ofA = sym.Pose3.from_storage(tmp).to_homogenous_matrix()\n",
    "            R_inB_ofA = T_inB_ofA[0:3, 0:3]\n",
    "            p_inB_ofA = T_inB_ofA[0:3, 3]\n",
    "            views[i_view]['R_inB_ofA'] = R_inB_ofA\n",
    "            views[i_view]['p_inB_ofA'] = p_inB_ofA\n",
    "        line = f.readline().split()\n",
    "        num_tracks = int(line[0])\n",
    "        num_invalid_new = 0\n",
    "        num_valid = 0\n",
    "        for i in range(num_tracks):\n",
    "            line = f.readline().split()\n",
    "            i_track = int(line[0])\n",
    "            track = tracks[i_track]\n",
    "            p_inA = np.array([float(n) for n in line[1:]])\n",
    "            track['p_inA'] = p_inA\n",
    "            valid = track['valid']\n",
    "            for match in track['matches']:\n",
    "                view_id = match['view_id']\n",
    "                feature_id = match['feature_id']\n",
    "                view = views[view_id]\n",
    "                R_inB_ofA = view['R_inB_ofA']\n",
    "                p_inB_ofA = view['p_inB_ofA']\n",
    "                p_inB = R_inB_ofA @ p_inA + p_inB_ofA\n",
    "                b = views[view_id]['pts'][feature_id]['pt2d']\n",
    "                e = sfm.projection_error(K, R_inB_ofA, p_inB_ofA, p_inA, b)\n",
    "                \n",
    "                # Remain valid if depth is positive\n",
    "                valid = valid and p_inB[2] > 0.\n",
    "                \n",
    "                # Remain valid if reprojection error is below threshold\n",
    "                valid = valid and e < max_reprojection_err\n",
    "            \n",
    "            track['valid'] = valid\n",
    "            if valid:\n",
    "                num_valid += 1\n",
    "            else:\n",
    "                num_invalid_new += 1\n",
    "\n",
    "\n",
    "    # Show diagnostics\n",
    "    print(f'{num_views:6d} views with updated pose estimate')\n",
    "    print(f'{num_valid:6d} valid tracks with updated position estimate')\n",
    "    print(f'{num_invalid_new:6d} newly invalid tracks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_cpp_to(views, tracks, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_process = subprocess.run([\n",
    "                    'optimization-cpp/build/BretlOptimize',\n",
    "                    str(Path('optimizer_to.txt').absolute()),\n",
    "                    str(Path('optimizer_from.txt').absolute()),\n",
    "                ], capture_output=True, text=True)\n",
    "print(completed_process.stdout)\n",
    "assert(completed_process.returncode == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_cpp_from(views, tracks, K, max_reprojection_err=max_reprojection_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm.show_results(views, tracks, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add visualization of results to the 3D viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfm.visualize_results(views, tracks, K, frames_per_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy results. If you want to start again from here, do the following:\n",
    "\n",
    "```python\n",
    "views, tracks = sfm.copy_results(views_1_opt, tracks_1_opt)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_1_opt, tracks_1_opt = sfm.copy_results(views, tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do dense reconstruction (a.k.a. two-view stereo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "img_A = views[0]['img']\n",
    "img_B = views[1]['img']\n",
    "\n",
    "# Get height and width of images\n",
    "img_height, img_width = img_A.shape\n",
    "\n",
    "# Get relative pose\n",
    "R_inB_ofA = views[1]['R_inB_ofA']\n",
    "p_inB_ofA = views[1]['p_inB_ofA']\n",
    "\n",
    "# Get the essential matrix\n",
    "E = sfm.skew(p_inB_ofA) @ R_inB_ofA\n",
    "\n",
    "# Get the fundamental matrix\n",
    "F = np.linalg.inv(K).T @ E @ np.linalg.inv(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example (point in sparse reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a point in image $A$ to find the depth of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a valid track to use as an example\n",
    "track = tracks[0]\n",
    "assert(track['valid'])\n",
    "\n",
    "# Get image coordinates\n",
    "match_A = sfm.get_match_with_view_id(track['matches'], 0)\n",
    "match_B = sfm.get_match_with_view_id(track['matches'], 1)\n",
    "a = sfm.get_pt2d_from_match(views, match_A)\n",
    "b_from_match = sfm.get_pt2d_from_match(views, match_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the epiline in image $B$ that corresponds to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_b_y(b_x, L):\n",
    "    return - (L[2] + b_x * L[0]) / L[1]\n",
    "\n",
    "# Get epipolar line\n",
    "L = F @ np.concatenate([a, [1.]])\n",
    "\n",
    "# Get endpoints of epipolar line segment\n",
    "b_x_0 = 0\n",
    "b_y_0 = get_b_y(b_x_0, L)\n",
    "b_x_1 = img_width - 1\n",
    "b_y_1 = get_b_y(b_x_1, L)\n",
    "\n",
    "# Get length of epipolar line segment (pixels)\n",
    "d = np.sqrt((b_x_1 - b_x_0)**2 + (b_y_1 - b_y_0)**2)\n",
    "\n",
    "# Sub-sample epipolar line segment at a fixed resolution\n",
    "step_px = 1.\n",
    "b_epipolar_line = np.array([\n",
    "    [b_x_i, get_b_y(b_x_i, L)] for b_x_i in np.linspace(b_x_0, b_x_1, int(1 + np.ceil(d / step_px)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the epiline in image $B$ that corresponds to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, (ax_A, ax_B) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "ax_A.set_xlim([0, img_width - 1])\n",
    "ax_A.set_ylim([img_height - 1, 0])\n",
    "ax_B.set_xlim([0, img_width - 1])\n",
    "ax_B.set_ylim([img_height - 1, 0])\n",
    "\n",
    "# Show images\n",
    "ax_A.imshow(img_A, cmap='gray')\n",
    "ax_B.imshow(img_B, cmap='gray')\n",
    "\n",
    "# Show epipolar line\n",
    "ax_B.plot(b_epipolar_line[:, 0], b_epipolar_line[:, 1], 'r-')\n",
    "\n",
    "# Show match\n",
    "ax_A.plot(a[0], a[1], 'r.', markersize=15)\n",
    "ax_B.plot(b_from_match[0], b_from_match[1], 'r.', markersize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set sum-squared difference in intensity values along epiline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a window size (pixels)\n",
    "win_size = 16\n",
    "\n",
    "# Window in image A\n",
    "win_A = cv2.getRectSubPix(img_A, [win_size, win_size], a)\n",
    "\n",
    "# Find SSD with windows along epipolar line\n",
    "ssd = []\n",
    "for b_i in b_epipolar_line:\n",
    "    win_B = cv2.getRectSubPix(img_B, [win_size, win_size], b_i)\n",
    "    ssd.append(np.sum((win_B - win_A)**2))\n",
    "ssd = np.array(ssd)\n",
    "\n",
    "# Find match (the point elong the epipolar line in image B with minimum SSD)\n",
    "i = np.argmin(ssd)\n",
    "b = b_epipolar_line[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, ((ax_A, ax_B), (ax_blank, ax_ssd)) = plt.subplots(2, 2, figsize=(15, 10), sharex=True)\n",
    "ax_blank.set_visible(False)\n",
    "ax_A.set_xlim([0, img_width - 1])\n",
    "ax_A.set_ylim([img_height - 1, 0])\n",
    "ax_B.set_xlim([0, img_width - 1])\n",
    "ax_B.set_ylim([img_height - 1, 0])\n",
    "\n",
    "# Show images\n",
    "ax_A.imshow(img_A, cmap='gray')\n",
    "ax_B.imshow(img_B, cmap='gray')\n",
    "\n",
    "# Show epipolar line\n",
    "ax_B.plot(b_epipolar_line[:, 0], b_epipolar_line[:, 1], 'r-')\n",
    "\n",
    "# Show match\n",
    "ax_A.plot(a[0], a[1], 'r.', markersize=15)\n",
    "ax_B.plot(b_from_match[0], b_from_match[1], 'r.', markersize=15)\n",
    "ax_B.plot(b[0], b[1], 'b.', markersize=10)\n",
    "\n",
    "# Show ssd\n",
    "ax_ssd.plot(b_epipolar_line[:, 0], ssd, 'r')\n",
    "ax_ssd.plot(b_epipolar_line[i, 0], ssd[i], 'b.', markersize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get depth\n",
    "alpha = np.linalg.inv(K) @ np.concatenate([a, [1.]])\n",
    "beta = np.linalg.inv(K) @ np.concatenate([b, [1.]])\n",
    "u = sfm.skew(beta) @ R_inB_ofA @ alpha\n",
    "v = - sfm.skew(beta) @ p_inB_ofA\n",
    "depth = (u.T @ v) / (u.T @ u)\n",
    "\n",
    "# Show depth\n",
    "print(f'depth = {depth:4.2f} (compare to {track[\"p_inA\"][2]:4.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example (point not in sparse reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a point in image $A$ to find the depth of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1000., 400.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the epiline in image $B$ that corresponds to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get epipolar line\n",
    "L = F @ np.concatenate([a, [1.]])\n",
    "\n",
    "# Get endpoints of epipolar line segment\n",
    "b_x_0 = 0\n",
    "b_y_0 = get_b_y(b_x_0, L)\n",
    "b_x_1 = img_width - 1\n",
    "b_y_1 = get_b_y(b_x_1, L)\n",
    "\n",
    "# Get length of epipolar line segment (pixels)\n",
    "d = np.sqrt((b_x_1 - b_x_0)**2 + (b_y_1 - b_y_0)**2)\n",
    "\n",
    "# Sub-sample epipolar line segment at a fixed resolution\n",
    "step_px = 1.\n",
    "b_epipolar_line = np.array([\n",
    "    [b_x_i, get_b_y(b_x_i, L)] for b_x_i in np.linspace(b_x_0, b_x_1, int(1 + np.ceil(d / step_px)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the epiline in image $B$ that corresponds to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, (ax_A, ax_B) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "ax_A.set_xlim([0, img_width - 1])\n",
    "ax_A.set_ylim([img_height - 1, 0])\n",
    "ax_B.set_xlim([0, img_width - 1])\n",
    "ax_B.set_ylim([img_height - 1, 0])\n",
    "\n",
    "# Show images\n",
    "ax_A.imshow(img_A, cmap='gray')\n",
    "ax_B.imshow(img_B, cmap='gray')\n",
    "\n",
    "# Show epipolar line\n",
    "ax_B.plot(b_epipolar_line[:, 0], b_epipolar_line[:, 1], 'r-')\n",
    "\n",
    "# Show match\n",
    "ax_A.plot(a[0], a[1], 'r.', markersize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set sum-squared difference in intensity values along epiline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a window size (pixels)\n",
    "win_size = 16\n",
    "\n",
    "# Window in image A\n",
    "win_A = cv2.getRectSubPix(img_A, [win_size, win_size], a)\n",
    "\n",
    "# Find SSD with windows along epipolar line\n",
    "ssd = []\n",
    "for b_i in b_epipolar_line:\n",
    "    win_B = cv2.getRectSubPix(img_B, [win_size, win_size], b_i)\n",
    "    ssd.append(np.sum((win_B - win_A)**2))\n",
    "ssd = np.array(ssd)\n",
    "\n",
    "# Find match (the point elong the epipolar line in image B with minimum SSD)\n",
    "i = np.argmin(ssd)\n",
    "b = b_epipolar_line[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, ((ax_A, ax_B), (ax_blank, ax_ssd)) = plt.subplots(2, 2, figsize=(15, 10), sharex=True)\n",
    "ax_blank.set_visible(False)\n",
    "ax_A.set_xlim([0, img_width - 1])\n",
    "ax_A.set_ylim([img_height - 1, 0])\n",
    "ax_B.set_xlim([0, img_width - 1])\n",
    "ax_B.set_ylim([img_height - 1, 0])\n",
    "\n",
    "# Show images\n",
    "ax_A.imshow(img_A, cmap='gray')\n",
    "ax_B.imshow(img_B, cmap='gray')\n",
    "\n",
    "# Show epipolar line\n",
    "ax_B.plot(b_epipolar_line[:, 0], b_epipolar_line[:, 1], 'r-')\n",
    "\n",
    "# Show match\n",
    "ax_A.plot(a[0], a[1], 'r.', markersize=15)\n",
    "ax_B.plot(b[0], b[1], 'b.', markersize=10)\n",
    "\n",
    "# Show ssd\n",
    "ax_ssd.plot(b_epipolar_line[:, 0], ssd, 'r')\n",
    "ax_ssd.plot(b_epipolar_line[i, 0], ssd[i], 'b.', markersize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get depth\n",
    "alpha = np.linalg.inv(K) @ np.concatenate([a, [1.]])\n",
    "beta = np.linalg.inv(K) @ np.concatenate([b, [1.]])\n",
    "u = sfm.skew(beta) @ R_inB_ofA @ alpha\n",
    "v = - sfm.skew(beta) @ p_inB_ofA\n",
    "depth = (u.T @ v) / (u.T @ u)\n",
    "\n",
    "# Show depth\n",
    "print(f'depth = {depth:4.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole image with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectify images to make all epipolar lines horizontal and parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R1, R2, P1, P2, Q, ROI1, ROI2 = cv2.stereoRectify(K, np.zeros(5), K, np.zeros(5), [img_width, img_height], R_inB_ofA, p_inB_ofA)\n",
    "mapX, mapY = cv2.initUndistortRectifyMap(K, np.zeros(5), R1, P1, [img_width, img_height], cv2.CV_32FC1)\n",
    "img_A_rectified = cv2.remap(img_A, mapX, mapY, cv2.INTER_CUBIC)\n",
    "mapX, mapY = cv2.initUndistortRectifyMap(K, np.zeros(5), R2, P2, [img_width, img_height], cv2.CV_32FC1)\n",
    "img_B_rectified = cv2.remap(img_B, mapX, mapY, cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show rectified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, (ax_A, ax_B) = plt.subplots(1, 2, figsize=(15, 10), sharex=True)\n",
    "\n",
    "# Show images\n",
    "ax_A.imshow(img_A_rectified, cmap='gray')\n",
    "ax_B.imshow(img_B_rectified, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create, apply, and show the results of a stereo matcher, following [this example](https://github.com/opencv/opencv/blob/master/samples/python/stereo_match.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stereo matcher\n",
    "win_size = 11\n",
    "min_disp = 0\n",
    "num_disp = 256 - min_disp\n",
    "stereo = cv2.StereoSGBM_create(\n",
    "    minDisparity=min_disp,\n",
    "    numDisparities=num_disp,\n",
    "    blockSize=16,\n",
    "    P1 = (8 * 3 * win_size**2),\n",
    "    P2 = (32 * 3 * win_size**2),\n",
    "    disp12MaxDiff = 1,\n",
    "    uniquenessRatio = 10,\n",
    "    speckleWindowSize = 100,\n",
    "    speckleRange = 32\n",
    ")\n",
    "\n",
    "# Apply stereo matcher\n",
    "disparity = stereo.compute(img_A_rectified, img_B_rectified)\n",
    "\n",
    "# Show results of stereo matcher\n",
    "plt.imshow(disparity)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions to ask yourself:\n",
    "* Is this the depth of points in image $A$ or image $B$?\n",
    "* Why do we get depth only of a subset of this image?\n",
    "* How would we assign a color to each point?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
